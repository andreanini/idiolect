% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/vectorize.R
\name{vectorize}
\alias{vectorize}
\title{Vectorize data}
\usage{
vectorize(
  input,
  tokens = "character",
  remove_punct = F,
  remove_symbols = T,
  remove_numbers = T,
  lowercase = T,
  n = 5,
  weighting = "rel",
  trim = T,
  threshold = 1500
)
}
\arguments{
\item{input}{This should be a \code{quanteda} corpus object with the author names as a docvar called "author".}

\item{tokens}{The type of tokens to extract, either "character" (default) or "word".}

\item{remove_punct}{A logical value. FALSE (default) keeps punctuation marks.}

\item{remove_symbols}{A logical value. TRUE (default) removes symbols.}

\item{remove_numbers}{A logical value. TRUE (default) removes numbers}

\item{lowercase}{A logical value. TRUE (default) transforms all tokens to lower case.}

\item{n}{The order or size of the n-grams being extracted. Default is 5.}

\item{weighting}{The type of weighting to use, "rel" for relative frequencies, "tf-idf".}

\item{trim}{A logical value. If TRUE (default) then only the most frequent tokens are kept.}

\item{threshold}{A numeric value indicating how many most frequent tokens to keep. The default is 1500.}
}
\value{
A dfm (document-feature matrix) containing each text as a feature vector. N-gram tokenisation does not cross sentence boundaries.
}
\description{
This function turns the texts into n-gram vectors.
}
\details{
More information about the literature will go here.
}
\examples{
mycorpus <- quanteda::corpus("The cat sat on the mat.")
quanteda::docvars(mycorpus, "author") <- "author1"
matrix <- vectorize(mycorpus)
}
