% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lambdaG_patterns.R
\name{lambdaG_patterns}
\alias{lambdaG_patterns}
\title{Extract patterns from the output of the LambdaG algorithm}
\usage{
lambdaG_patterns(q.data, k.data, ref.data, N = 10, r = 30, cores = NULL)
}
\arguments{
\item{q.data}{A single questioned or disputed text as a \code{quanteda} tokens object with the tokens being sentences (e.g. the output of \code{\link[=tokenize_sents]{tokenize_sents()}}).}

\item{k.data}{A known or undisputed corpus containing exclusively a single candidate author's texts as a \code{quanteda} tokens object with the tokens being sentences (e.g. the output of \code{\link[=tokenize_sents]{tokenize_sents()}}).}

\item{ref.data}{The reference dataset as a \code{quanteda} tokens object with the tokens being sentences (e.g. the output of \code{\link[=tokenize_sents]{tokenize_sents()}}).}

\item{N}{The order of the model. Default is 10. It cannot be 1.}

\item{r}{The number of iterations. Default is 30.}

\item{cores}{The number of cores to use for parallel processing (the default is one).}
}
\value{
The function outputs a data frame with each row being an extracted pattern from the Q text, with the context, token, n-gram length, the probability of the token given the context in the Q text, the probability of the token given the context in the K text, and the lambdaG value for the pattern.
}
\description{
This function extracts the patterns from the output of the LambdaG algorithm (Nini et al. under review).
}
\examples{
q.data <- corpus_trim(enron.sample[1], "sentences", max_ntoken = 10) |> quanteda::tokens("sentence")
k.data <- enron.sample[2:5]|> quanteda::tokens("sentence")
ref.data <- enron.sample[6:ndoc(enron.sample)] |> quanteda::tokens("sentence")
lambdaG_patterns(q.data, k.data, ref.data, r = 2)

}
\references{
Nini, A., Halvani, O., Graner, L., Gherardi, V., Ishihara, S. Authorship Verification based on the Likelihood Ratio of Grammar Models. https://arxiv.org/abs/2403.08462v1
}
