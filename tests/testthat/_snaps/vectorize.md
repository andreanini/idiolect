# tokenisation and vectorisation are correct

    Code
      vectorize(mycorpus)
    Output
      Document-feature matrix of: 24 documents, 1,969 features (85.35% sparse) and 2 docvars.
                      features
      docs                   , the       the        the b       he ba        back
        allen-p_16.txt 0.002427184 0.03640777 0.002427184 0.002427184 0.002427184
        allen-p_37.txt 0.003003003 0.01201201 0           0           0          
        allen-p_49.txt 0           0.02739726 0           0           0          
        allen-p_57.txt 0           0.01666667 0.004166667 0           0.004166667
        allen-p_72.txt 0.001655629 0.01324503 0           0           0          
        allen-p_84.txt 0.001845018 0.01937269 0           0           0          
                      features
      docs                   back        ack o       ck of        offi       offic
        allen-p_16.txt 0.002427184 0.002427184 0.002427184 0.009708738 0.009708738
        allen-p_37.txt 0           0           0           0           0          
        allen-p_49.txt 0           0           0           0.002739726 0.002739726
        allen-p_57.txt 0.004166667 0.004166667 0.004166667 0           0          
        allen-p_72.txt 0           0           0           0           0          
        allen-p_84.txt 0           0           0           0           0          
      [ reached max_ndoc ... 18 more documents, reached max_nfeat ... 1,959 more features ]

