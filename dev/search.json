[{"path":"https://andreanini.github.io/idiolect/dev/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to idiolect","title":"Contributing to idiolect","text":"outlines propose change idiolect.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to idiolect","text":"can fix typos, spelling mistakes, grammatical errors documentation directly using GitHub web interface, long changes made source file. generally means ’ll need edit roxygen2 comments .R, .Rd file. can find .R file generates .Rd reading comment first line.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/CONTRIBUTING.html","id":"bigger-changes","dir":"","previous_headings":"","what":"Bigger changes","title":"Contributing to idiolect","text":"want make bigger change, ’s good idea first file issue make sure someone team agrees ’s needed. ’ve found bug, please file issue illustrates bug minimal reprex (also help write unit test, needed). See guide create great issue advice.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/CONTRIBUTING.html","id":"pull-request-process","dir":"","previous_headings":"Bigger changes","what":"Pull request process","title":"Contributing to idiolect","text":"Fork package clone onto computer. haven’t done , recommend using usethis::create_from_github(\"andreanini/idiolect\", fork = TRUE). Install development dependencies devtools::install_dev_deps(), make sure package passes R CMD check running devtools::check(). R CMD check doesn’t pass cleanly, ’s good idea ask help continuing. Create Git branch pull request (PR). recommend using usethis::pr_init(\"brief-description--change\"). Make changes, commit git, create PR running usethis::pr_push(), following prompts browser. title PR briefly describe change. body PR contain Fixes #issue-number. user-facing changes, add bullet top NEWS.md (.e. just first header). Follow style described https://style.tidyverse.org/news.html.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/CONTRIBUTING.html","id":"code-style","dir":"","previous_headings":"Bigger changes","what":"Code style","title":"Contributing to idiolect","text":"New code follow tidyverse style guide. can use styler package apply styles, please don’t restyle code nothing PR. use roxygen2, Markdown syntax, documentation. use testthat unit tests. Contributions test cases included easier accept.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 2, June 1991Copyright © 1989, 1991 Free Software Foundation, Inc.,51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"licenses software designed take away freedom share change . contrast, GNU General Public License intended guarantee freedom share change free software–make sure software free users. General Public License applies Free Software Foundation’s software program whose authors commit using . (Free Software Foundation software covered GNU Lesser General Public License instead.) can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge service wish), receive source code can get want , can change software use pieces new free programs; know can things. protect rights, need make restrictions forbid anyone deny rights ask surrender rights. restrictions translate certain responsibilities distribute copies software, modify . example, distribute copies program, whether gratis fee, must give recipients rights . must make sure , , receive can get source code. must show terms know rights. protect rights two steps: (1) copyright software, (2) offer license gives legal permission copy, distribute /modify software. Also, author’s protection , want make certain everyone understands warranty free software. software modified someone else passed , want recipients know original, problems introduced others reflect original authors’ reputations. Finally, free program threatened constantly software patents. wish avoid danger redistributors free program individually obtain patent licenses, effect making program proprietary. prevent , made clear patent must licensed everyone’s free use licensed . precise terms conditions copying, distribution modification follow.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/LICENSE.html","id":"terms-and-conditions-for-copying-distribution-and-modification","dir":"","previous_headings":"","what":"TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION","title":"GNU General Public License","text":"0. License applies program work contains notice placed copyright holder saying may distributed terms General Public License. “Program”, , refers program work, “work based Program” means either Program derivative work copyright law: say, work containing Program portion , either verbatim modifications /translated another language. (Hereinafter, translation included without limitation term “modification”.) licensee addressed “”. Activities copying, distribution modification covered License; outside scope. act running Program restricted, output Program covered contents constitute work based Program (independent made running Program). Whether true depends Program . 1. may copy distribute verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice disclaimer warranty; keep intact notices refer License absence warranty; give recipients Program copy License along Program. may charge fee physical act transferring copy, may option offer warranty protection exchange fee. 2. may modify copy copies Program portion , thus forming work based Program, copy distribute modifications work terms Section 1 , provided also meet conditions: ) must cause modified files carry prominent notices stating changed files date change. b) must cause work distribute publish, whole part contains derived Program part thereof, licensed whole charge third parties terms License. c) modified program normally reads commands interactively run, must cause , started running interactive use ordinary way, print display announcement including appropriate copyright notice notice warranty (else, saying provide warranty) users may redistribute program conditions, telling user view copy License. (Exception: Program interactive normally print announcement, work based Program required print announcement.) requirements apply modified work whole. identifiable sections work derived Program, can reasonably considered independent separate works , License, terms, apply sections distribute separate works. distribute sections part whole work based Program, distribution whole must terms License, whose permissions licensees extend entire whole, thus every part regardless wrote . Thus, intent section claim rights contest rights work written entirely ; rather, intent exercise right control distribution derivative collective works based Program. addition, mere aggregation another work based Program Program (work based Program) volume storage distribution medium bring work scope License. 3. may copy distribute Program (work based , Section 2) object code executable form terms Sections 1 2 provided also one following: ) Accompany complete corresponding machine-readable source code, must distributed terms Sections 1 2 medium customarily used software interchange; , b) Accompany written offer, valid least three years, give third party, charge cost physically performing source distribution, complete machine-readable copy corresponding source code, distributed terms Sections 1 2 medium customarily used software interchange; , c) Accompany information received offer distribute corresponding source code. (alternative allowed noncommercial distribution received program object code executable form offer, accord Subsection b .) source code work means preferred form work making modifications . executable work, complete source code means source code modules contains, plus associated interface definition files, plus scripts used control compilation installation executable. However, special exception, source code distributed need include anything normally distributed (either source binary form) major components (compiler, kernel, ) operating system executable runs, unless component accompanies executable. distribution executable object code made offering access copy designated place, offering equivalent access copy source code place counts distribution source code, even though third parties compelled copy source along object code. 4. may copy, modify, sublicense, distribute Program except expressly provided License. attempt otherwise copy, modify, sublicense distribute Program void, automatically terminate rights License. However, parties received copies, rights, License licenses terminated long parties remain full compliance. 5. required accept License, since signed . However, nothing else grants permission modify distribute Program derivative works. actions prohibited law accept License. Therefore, modifying distributing Program (work based Program), indicate acceptance License , terms conditions copying, distributing modifying Program works based . 6. time redistribute Program (work based Program), recipient automatically receives license original licensor copy, distribute modify Program subject terms conditions. may impose restrictions recipients’ exercise rights granted herein. responsible enforcing compliance third parties License. 7. , consequence court judgment allegation patent infringement reason (limited patent issues), conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. distribute satisfy simultaneously obligations License pertinent obligations, consequence may distribute Program . example, patent license permit royalty-free redistribution Program receive copies directly indirectly , way satisfy License refrain entirely distribution Program. portion section held invalid unenforceable particular circumstance, balance section intended apply section whole intended apply circumstances. purpose section induce infringe patents property right claims contest validity claims; section sole purpose protecting integrity free software distribution system, implemented public license practices. Many people made generous contributions wide range software distributed system reliance consistent application system; author/donor decide willing distribute software system licensee impose choice. section intended make thoroughly clear believed consequence rest License. 8. distribution /use Program restricted certain countries either patents copyrighted interfaces, original copyright holder places Program License may add explicit geographical distribution limitation excluding countries, distribution permitted among countries thus excluded. case, License incorporates limitation written body License. 9. Free Software Foundation may publish revised /new versions General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies version number License applies “later version”, option following terms conditions either version later version published Free Software Foundation. Program specify version number License, may choose version ever published Free Software Foundation. 10. wish incorporate parts Program free programs whose distribution conditions different, write author ask permission. software copyrighted Free Software Foundation, write Free Software Foundation; sometimes make exceptions . decision guided two goals preserving free status derivatives free software promoting sharing reuse software generally.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/LICENSE.html","id":"no-warranty","dir":"","previous_headings":"","what":"NO WARRANTY","title":"GNU General Public License","text":"11. PROGRAM LICENSED FREE CHARGE, WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION. 12. EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MAY MODIFY /REDISTRIBUTE PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES. END TERMS CONDITIONS","code":""},{"path":"https://andreanini.github.io/idiolect/dev/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively convey exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program interactive, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, commands use may called something show w show c; even mouse-clicks menu items–whatever suits program. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. sample; alter names: General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 2 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program; if not, write to the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA. Gnomovision version 69, Copyright (C) year name of author Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'. This is free software, and you are welcome to redistribute it under certain conditions; type `show c' for details. Yoyodyne, Inc., hereby disclaims all copyright interest in the program `Gnomovision' (which makes passes at compilers) written by James Hacker.  <signature of Ty Coon>, 1 April 1989 Ty Coon, President of Vice"},{"path":"https://andreanini.github.io/idiolect/dev/articles/idiolect.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"idiolect","text":"Authorship Analysis defined task determining likelihood certain candidate author certain set questioned disputed texts. call Forensic Authorship Analysis task kind applied real forensic case. Forensic Linguistics, typically: QQ indicates set disputed questioned texts. KK indicates texts written candidate author collected comparison material. indicate RR reference dataset might compiled analyst specific case (Ishihara et al. 2024). example, QQ text text committing crime, threatening letter, text evidence investigation, set text messages. KK set texts authored suspect author QQ. Finally, RR made texts comparable QQ KK, example genre/register, mode production, parameter linguist maintains important analysis particular case. crucial difference Authorship Analysis Forensic Authorship Analysis whereas former can treated classification task final answer binary (‘candidate author’ vs. ‘candidate author’), latter needs expression likelihood two competing propositions hypotheses, Prosecution Hypothesis HpH_p vs. Defence Hypothesis HdH_d, example: HpH_p: author KK author QQ individual.HdH_d: author KK author QQ two different individuals. job forensic linguist forensic context analyse linguistic evidence determine hypothesis supports degree strength, thus aiding trier--fact reaching conclusion. role forensic linguist therefore provide YES/answer rather express strength evidence favour two hypotheses. Given KK, QQ RR, workflow analysis involves four steps: Preparation: step involves pre-processing step necessary analysis chosen method. Validation: Carry analysis case data separate dataset designed similar case material order validate chosen method works particular case. Even though methods contained idiolect tested various published academic studies, also important methods tested (.e. validated) specific case (Ishihara et al. 2024). Analysis: Carry analysis real KK, QQ, RR. Calibration: Turn output (3) Likelihood Ratio expresses strength evidence given two competing hypotheses.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/articles/idiolect.html","id":"preparation","dir":"Articles","previous_headings":"","what":"Preparation","title":"idiolect","text":"input key functions idiolect quanteda corpus object two docvars: author, containing unique names authors text, textname, name text. Users can create corpus using quanteda. guidance create corpus quanteda see page. However, users less experienced quanteda, idiolect convenience function called create_corpus() import texts format starting folder plain texts. function simply calling readtext (therefore package must installed) scanning name files metadata text, specifically name author name file. syntax follow name files : authorname_textname.txt (e.g. smith_text1.txt). Assuming folder plain text files names according syntax ready user’s computer, following command (executed ) loads folder quanteda corpus object containing required docvars. vignette, instead, rest workflow demonstrated using small dataset Enron corpus included package (see ?enron.sample). corpus quanteda corpus object contains ten authors approximately amount data.","code":"corpus <- create_corpus(\"path/to/folder\") corpus <- enron.sample"},{"path":"https://andreanini.github.io/idiolect/dev/articles/idiolect.html","id":"content-masking","dir":"Articles","previous_headings":"Preparation","what":"Content masking","title":"idiolect","text":"highly recommended sometimes necessary pre-processing step content masking. step consists masking removing words tokens text likely create noise authorship analysis. Hiding content avoids incorrectly attributing text based correlation topics authors (Bischoff et al. 2020) also tends improve performance authorship analysis methods cross-topic cross-genre situations (Stamatatos 2017). Three content masking methods implemented idiolect: (1) POSnoise algorithm developed Halvani Graner (2021); (2) frame n-grams approach introduced Nini (2023); (3) implementation TextDistortion approach originally introduced Stamatatos (2017). options available contentmask() function. function depends spacyr requires downloading parsing model language automatic tagging Parts Speech (e.g. nouns, adjectives, adverbs), function run vignette. Instead, Enron sample already content-masked using POSnoise, can seen preview corpus POSnoise algorithm essentially replaces words tend contain meaning (nouns, verbs, adjectives, adverbs) Part Speech tag (N, V, J, B) words tokens left unchanged. addition operation, POSnoise contains white list content words mostly tend functional English, verbs like , , make adverbs consequently, therefore. following code used run contentmask() function. require installing initiating spacy parsing model language chosen. process happen automatically. installation start automatically, installatino spacyr package default model can done follows:","code":"corpus #> Corpus consisting of 49 documents and 2 docvars. #> Kevin_h_Mail_1 : #> \"N N N N wants to be N when he V up likes N P , N for doing t...\" #>  #> Kevin_h_Mail_3 : #> \"i 've V a J one , but the only N N N i have is on a N N from...\" #>  #> Kevin_h_Mail_4 : #> \"this was J towards the N of a J N N N . in N , P P helped th...\" #>  #> Kevin_h_Mail_5 : #> \"V the N for more than D N may get you V . a N N with a N and...\" #>  #> Kevin_h_Mail_2 : #> \"P , here 's the J N on our P P N V to V the V needs of the P...\" #>  #> Kimberly_w_Mail_3 : #> \"they also have J N at the J N of P D per N and only a D J ea...\" #>  #> [ reached max_ndoc ... 43 more documents ] posnoised.corpus <- contentmask(corpus, model = \"en_core_web_sm\", algorithm = \"POSnoise\") install.packages(\"spacyr\") spacyr::install_spacy()"},{"path":"https://andreanini.github.io/idiolect/dev/articles/idiolect.html","id":"data-labelling","dir":"Articles","previous_headings":"Preparation","what":"Data labelling","title":"idiolect","text":"example simulated Kimberly_w_Mail_3, written author Kimberly_w, real QQ text known texts written Kimberly_w therefore set known texts KK. remaining texts authors reference samples RR.","code":"Q <- corpus_subset(corpus, author == \"Kimberly_w\" & textname == \"Mail_3\") K <- corpus_subset(corpus, author == \"Kimberly_w\" & textname != \"Mail_3\") R <- corpus_subset(corpus, author != \"Kimberly_w\")"},{"path":"https://andreanini.github.io/idiolect/dev/articles/idiolect.html","id":"vectorisation","dir":"Articles","previous_headings":"Preparation","what":"Vectorisation","title":"idiolect","text":"applying certain authorship analysis methods, text sample must turned numerical representation called feature vector, process typically referred vectorisation. idiolect function vectorise corpus called vectorize(). features normally used many authorship analysis methods nn-grams words punctuation marks characters. example, QQ text can vectorised relative frequencies words using code. , frequent 1000 character 4-grams relative frequencies, example, using output function quanteda document-feature matrix (dfm) can efficiently store even large matrices. vectorize() function mostly designed expert users different choices parameters vectorisation can made using single authorship analysis method function. addition, since authorship analysis methods already default setting parameters, already default authorship analysis functions. step therefore necessary unless specific requirements, vectorisation handled functions apply authorship analysis methods.","code":"vectorize(Q, tokens = \"word\", remove_punct = FALSE, remove_symbols = TRUE, remove_numbers = TRUE,           lowercase = TRUE, n = 1, weighting = \"rel\", trim = FALSE) |>    print(max_nfeat = 3) #> Document-feature matrix of: 1 document, 136 features (0.00% sparse) and 2 docvars. #>                    features #> docs                      they        also      have #>   Kimberly_w_Mail_3 0.00289296 0.009643202 0.0192864 #> [ reached max_nfeat ... 133 more features ] vectorize(Q, tokens = \"character\", remove_punct = FALSE, remove_symbols = TRUE, remove_numbers = TRUE,           lowercase = TRUE, n = 4, weighting = \"rel\", trim = TRUE, threshold = 1000) |>    print(max_nfeat = 3) #> Document-feature matrix of: 1 document, 1,094 features (0.00% sparse) and 2 docvars. #>                    features #> docs                        they         hey          ey a #>   Kimberly_w_Mail_3 0.0009771987 0.0009771987 0.0003257329 #> [ reached max_nfeat ... 1,091 more features ]"},{"path":"https://andreanini.github.io/idiolect/dev/articles/idiolect.html","id":"validation","dir":"Articles","previous_headings":"","what":"Validation","title":"idiolect","text":"first step validation remove real QQ text. actual forensic sample analyse must therefore removed validating analysis. validation set therefore made KK RR datasets dataset must now re-divided ‘fake’ QQ texts ‘fake’ KK texts. create two new disjoint datasets, validation.Q validation.K, randomly sample one text author ‘fake’ QQ leave rest ‘fake’ KK texts. way validation analysis can conducted. completely different dataset similar case data used, example. simpler approach suitable small example.","code":"validation <- K + R validation.Q <- corpus_sample(validation, size = 1, by = author) validation.K <- corpus_subset(validation, !docnames(validation) %in% docnames(validation.Q))"},{"path":"https://andreanini.github.io/idiolect/dev/articles/idiolect.html","id":"authorship-analysis","dir":"Articles","previous_headings":"Validation","what":"Authorship analysis","title":"idiolect","text":"example, scenario simulated verification: unknown QQ text written KK author, Kimberly_w? reason, method chosen one successful authorship verification methods available present, Impostors Method (Koppel Winter 2014), particular one latest variants called Rank-Based Impostors Method (Potha Stamatatos 2017, 2020). analysis can run idiolect using function impostors() selecting default parameter algorithm argument, “RBI”. main argument function q.data, set QQ texts test, k.data, set KK texts one authors going tested, finally set impostors data, cand.imps. example, impostors data RR set generally recommendation use another dataset possible. impostors() function accepts one author k.data also accepts dataset input k.data cand.imps. dataset used, impostors() test author k.data use texts written authors impostors. contrast authorship analysis functions like delta() ngram_tracing(), impostors() offer additional parameters modify vectorisation process Impostors Method algorithms already well-specified default setting. user wants change vectorise corpus separately using vectorize() use dfm input impostors(). RBI variant method requires setting parameter called kk, number similar impostors texts sample wider set impostors. recommended setting k=100k=100 k=300k=300 simplicity set k=10k=10 example. realistic setting used example. analysis using Impostors Method can long run times, function can also parallelised using one core. output impostors() data frame showing results comparing KK author QQ text. variable target TRUE comparison -author one FALSE different-author one. variable score contains Impostors score, value ranges 0 1. authorship analysis functions return data frame type columns. variable score therefore represents different quantities depending analysis function used (e.g. delta(), Δ\\Delta coefficient, ). order assess results validation analysis, function performance() can used return series performance metrics. function can take one two result data frames input. two provided, one used training one test. one data frame provided, performance metrics calculated using leave-one-approach. procedure followed function held one text (leave-one-, otherwise test dataset entirety) use rest data (training dataset) calibration dataset calculate Log-Likelihood Ratio (LLRLLR). analysis done using calibrate_LLR() function, fits logistic regression model calibrate score LLRLLRIshihara (2021) using ROC library (Leeuwen 2015). output function following: CllrC_{llr} CllrminC_{llr}^{min} coefficients used evaluate performance LLRLLR system (Ramos et al. 2013). coefficients estimate accuracy LLRLLR, value 1 indicates chance-level accuracy lower coefficient Cllr<1C_{llr}<1 suggests valuable information results, lower values CllrC_{llr} suggesting better performance. binary classification metrics returned, Precision, Recall, F1, calculated using LLR>0LLR > 0 threshold TRUE (-author case) classification. present example, Cllr=C_{llr}= 0.798 suggests performance acceptable able proceed actual forensic analysis. CllrminC_{llr}^{min}, component CllrC_{llr} measuring amount discrimination, even lower, means substantial difference two distributions. confirmed Area Curve value 0.777. large disparity TRUE FALSE test cases, values Precision F1 misleading. Balanced Accuracy value 0.767, however, suggests substantial amount discrimination LLR=0LLR=0. results analysis can also plotted using density plot two distributions, TRUE FALSE. can done using density_plot() function  plot shows values score horizontal axis density TRUE (blue) vs. FALSE (red) vertical axis. findings evidence method validated dataset now possible analyse QQ text use results calibrate LLRLLR QQ.","code":"res <- impostors(validation.Q, validation.K, validation.K, algorithm = \"RBI\", k = 10) res[1:10,] #>             K                 Q target score #> 1  Kimberly_w    Kevin_h_Mail_1  FALSE 0.750 #> 2  Kimberly_w Kimberly_w_Mail_5   TRUE 1.000 #> 3  Kimberly_w    Larry_c_Mail_2  FALSE 0.500 #> 4  Kimberly_w    Lindy_d_Mail_3  FALSE 0.833 #> 5  Kimberly_w      Liz_t_Mail_4  FALSE 0.667 #> 6  Kimberly_w   Louise_k_Mail_2  FALSE 0.667 #> 7  Kimberly_w     Lynn_b_Mail_3  FALSE 1.000 #> 8  Kimberly_w     Lysa_a_Mail_5  FALSE 0.500 #> 9  Kimberly_w        M_f_Mail_3  FALSE 0.750 #> 10 Kimberly_w        M_l_Mail_2  FALSE 0.833 p <- performance(res, progress = FALSE) p$evaluation #>        Cllr  Cllr_min      EER Mean TRUE LLR Mean FALSE LLR TRUE trials #> 1 0.7979282 0.7183427 26.26582     0.4062006     -0.4368895          12 #>   FALSE trials       AUC Balanced Accuracy Precision Recall        F1 TP FN FP #> 1           92 0.7766667         0.7666667      0.25    0.8 0.3809524  8  2 24 #>   TN #> 1 66 density_plot(res)"},{"path":"https://andreanini.github.io/idiolect/dev/articles/idiolect.html","id":"analysis-of-q","dir":"Articles","previous_headings":"","what":"Analysis of QQ","title":"idiolect","text":"point thing left analyse forensic data feeding real QQ, KK, RR impostors() function using settings used validation. one QQ text, final table results contains one row","code":"q.res <- impostors(Q, K, R, algorithm = \"RBI\", k = 10) q.res #>            K                 Q target score #> 1 Kimberly_w Kimberly_w_Mail_3   TRUE     1"},{"path":"https://andreanini.github.io/idiolect/dev/articles/idiolect.html","id":"qualitative-examination-of-evidence","dir":"Articles","previous_headings":"Analysis of QQ","what":"Qualitative examination of evidence","title":"idiolect","text":"reaching conclusions, often important inspect features algorithm considered analysis. forensic analysis, good knowledge data important best practice require analyst familiar dataset running computational analysis. Reading data familiar can lead addition pre-processing steps remove noise can help analyst spot problem mistakenly introduced algorithm. addition familiarise data, idiolect allows analyst explore important feature considered authorship analysis method used. example, using RBI algorithm impostors() parameter features can switched TRUE obtain list important features. Running parameter switched produces following results RBI method uses features character 4-grams list features clearly hard interpret human analyst. Despite complexity, impossible task. idiolect offers function aid exploration called concordance(), uses quanteda’s kwic() engine. concordance() takes input string representing one words (punctuation marks). example, one important character 4-gram seems <, > search target. search reveals character sequence strong characteristic candidate author’s writing. However, real underlying pattern use comma followed possessive determiner token sequence [, ], used candidate author one author reference corpus. Another important feature represented two character 4-grams, <lso ,> <, >, likely refer token sequence [also ,]. correct referring use also beginning sentence immediately followed comma. Although searching features returned clearly significant amount work, inspecting list features carefully using concordance() explore features data analyst can spot patterns mistakes analysis (Ypma, Ramos, Meuwly 2023).","code":"q.res2 <- impostors(Q, K, R, algorithm = \"RBI\", k = 10, features = TRUE) strwrap(q.res2$features, width = 70) #>  [1] \"to me|o me |, her| P on|P on |re al|ve no|i jus|lso ,|so , |P P f|N N\" #>  [2] \".|also |ll me|l me | also| N i |e N s| few |you n|ou ne|u nee|our\"     #>  [3] \"J|ur J |ust w|st wa|few N|ew N |P P V|ve a | him |as i | , he|u\"       #>  [4] \"and|the J|he J |V J N|u hav|, i w|P P i|N N N|P P o|, N a|do no|o\"     #>  [5] \"not|P D .|you h|ou ha| too |re is|s for|r N o| P in|P in |our P|ur P\"  #>  [6] \"| P fo|P for| may | at t|e a N|o V i| P to|P to |o be |lso V|so V\"     #>  [7] \"|thing|hing |V it |is J |r N w|P , h|nd th|ou an|to do|o do | two |\"   #>  [8] \"we w| do n|rom P|om P | N fr|ave n|e N w| here|t is |but i|, i h|\"     #>  [9] \"into|into | we V| yet |you N|ou N |ke a | V it|ave a|ng th|s N N|n P\"  #> [10] \",| our |s you|N fro|ere i|N who|me N | see | N or|N or |is V | can |\"  #> [11] \"we '|ut i | V wi|V wit|P , w|V our|N for| but |an V | one |ome N| N\"   #> [12] \"fo|ave b|or V |other| to m| is o| a N | J N |e hav|J N o|e tha|\"       #> [13] \"look|i am | , bu|, but|eithe|ither|P P .|t wan|can V|t to |in P |in V\" #> [14] \"|to se| N J |ore N| get |N in |N , N| as i| in P|e is |ith y|th yo|h\"  #> [15] \"you|e J N|ve V | , th|n N .| i ha|some | is J|are a|e an |i hav|\"      #> [16] \"othe|this | a J |a N N|my N | is a| J fo|J for|e thi|n our|s the|may\"  #> [17] \"b|ay be|y be |ase l|se le|e let|o see|did n|o hav| V ou| it .|\"        #> [18] \"some|or P | N on| P 's|P 's | is V| so i|d the|d you| , i |e P P|n\"    #> [19] \"you|if yo| you |is a |the N|he N | B , |P , P|t V a|and t| this|N on\"  #> [20] \"|a N t|V tha|want |in a |e wil|a N f| , so|ther |we ar| have|i wil|\"   #> [21] \"my N|have | P N |o V o| V J |hat P|r N a|t the|a J N| V an| 's N|'s N\" #> [22] \"|P P P| the | N if|N if | P is|at i | work| on P|on P |with |N , b|N\"  #> [23] \"has|a N a|ant t|nt to|ow if|w if |V and|ake a| in a|e of | are |is N\"  #> [24] \"|as V | week|week | J in|J in | N of|N of |e V i|V to |or N |, we |to\" #> [25] \"be| to b|N N o|e you| V to| V my|V my |r J N| V fo|V for|you t|V thi|\" #> [26] \"to s| know|e N N|V in |f you| , wh| V a |me to| N in|t kno|u to |ed\"   #> [27] \"to|his N|P P N|fter | me t| star|start|the P|he P |know |for t|out w|\" #> [28] \"'ll | N th| was |now i|N V N| afte|P , a|r N i|ere w|ach o|ch of|h of\" #> [29] \"|o J N|i 'll|after|r D N|ill h| it t|ether|e als|P tha|o V .|\"         #> [30] \"only|nning|ning |y N N|e V y|ou to| out |se V |ase V|J N ,| just|\"     #> [31] \"each|each |ill V|t you|eek .|are V|look |o mak|only |ou wo| P D |l\"    #> [32] \"hav|worki|orkin|rking|to ma|at yo|tart | N P |our N|ur N | both|both\"  #> [33] \"|e in | of N|of N |J N .|V you| give|N N a|and g|just |at P |o the|t\"  #> [34] \"V i|e and|s to | in t|here |V any|o V y| by N|ll V |o you| , as|, as\"  #> [35] \"|N we |e J t|in th| , we|n the|needs|eeds |ll ha|for N|hat y| N we|re\" #> [36] \"V |N N ,|N N i|your |s N ,|is th|ve an|by th| V yo| , yo|,\"            #> [37] \"you|pleas|lease|ease |re J | call|e nee|y N .| and |make |P is |N\"     #> [38] \"tha|ough |by N | if y|t i w|s tha|V a N| is t|o V u| me a|her N|you\"   #> [39] \"a|e V a|call |V the| any |er N | be V|be V |e wou|or th| plea| she\"    #> [40] \"|at we|more |P P a| P th| J , |or D |we ne|e to | P , | we n|ing o|t\"  #> [41] \"thi| V in| that|r P P|we wo| N an|e N .|N and|o V N| J to|J to | P V\"  #> [42] \"|d to | V N |ch N | has | did | V on|hat i|V P P|r our| N by|N by |th\" #> [43] \"N | a fe|a few|V N o| a D |d lik|e V f|i wou|hat h|ke to|ill n|\"       #> [44] \"find|find |ld li|uld l| per | let |N , s|N , h|ike t|ve be|e bee|for\"  #> [45] \"h|y hav|s N w| woul|would| like|like |e if | be J|be J |ith P|th P\"    #> [46] \"|in N |e V t| P ha|give |ow wh|ee if|you m|and i|o V t| to V|to V |\"   #> [47] \"on t| with|ted t|or yo| , pl|, ple|P and|at th| make|for y|t me |now\"  #> [48] \"w|not V|and h| P an|o P P|let m|et me| me k|me kn|e kno|ith N| V up|V\" #> [49] \"up | i am| in N|any N|ny N |J N N| will|ot V |d P P| i V | , P |r N\"   #> [50] \".|f the|ould |eed t| N wi|nd i | for |ome o|me of|t wit|f N .|o V w|\"  #> [51] \"N so|N so |m to |ne of|e V .|king | them|them |one o|to ta|n to |we\"   #> [52] \"ha| your|id no|see i|hat N|e J .|ave V| N B |nd N |o V a| of y|of\"     #> [53] \"yo|and N| N N | what| to t|to ge|o get|a N o| if t|e V N| we h| V\"     #> [54] \"th|i nee|if we|f we |oing |r the| from| had | N , |d not|e N o|u V t|\" #> [55] \"want|need |from | , N |N V t\" concordance(Q, K, R, search = \", her\", token.type = \"character\") |>    dplyr::select(pre, node, post, authorship) #>      pre  node  post authorship #> 1   . P  , her e is           Q #> 2  we V  , her e is           Q #> 3   . P  , her e is           Q #> 4  ur N  , her e is           K #> 5   . P  , her e is           K #> 6   . P  , her e is           K #> 7  nd P  , her e is           K #> 8   . P  , her e is           K #> 9   N N  , her e is           K #> 10 st P  , her e is           K #> 11  N N  , her e is           K #> 12    P  , her e 's   Reference #> 13  P P  , her e out  Reference #> 14 nd P  , her e is   Reference #> 15  . P  , her e are  Reference #> 16  . P  , her e are  Reference concordance(Q, K, R, search = \", here is\", token.type = \"word\") |>    dplyr::select(pre, node, post, authorship) #>                 pre      node                   post authorship #> 1   each of you . P , here is           the P P P on          Q #> 2    on this N we V , here is          a N N of both          Q #> 3       N for P . P , here is            the P P P P          Q #> 4  all . per your N , here is          some J N on P          K #> 5       B and V . P , here is           the J N N on          K #> 6         N V N . P , here is            the P P P P          K #> 7       N . P and P , here is        the J for the P          K #> 8       N N yet . P , here is            the P P P P          K #> 9    out of the N N , here is the beginning of the N          K #> 10 N on this past P , here is  the N we talked about          K #> 11   as per our N N , here is            the V P P P          K #> 12   know . P and P , here is            a N of N in  Reference concordance(Q, K, R, search = \"lso ,\", token.type = \"character\") |>    dplyr::select(pre, node, post, authorship) #>      pre  node  post authorship #> 1  N ? a lso ,  ther          Q #> 2  V . a lso ,  i ha          Q #> 3  P . a lso ,  plea          Q #> 4  k . a lso ,  P ha          Q #> 5  N . a lso ,  P P           K #> 6  N . a lso ,  at t          K #> 7  N ? a lso ,  i 'v          K #> 8  s . a lso ,  let           K #> 9      a lso ,  V th          K #> 10 N . a lso ,  i V           K #> 11 N . a lso ,  woul  Reference #> 12 . P a lso ,  V to  Reference #> 13 N . a lso ,  any   Reference #> 14 N . a lso ,  have  Reference #> 15 P . a lso ,  P P   Reference #> 16 N . a lso ,  you   Reference #> 17 D . a lso ,  to V  Reference #> 18 N . a lso ,  tell  Reference #> 19 J . a lso ,  coul  Reference #> 20 N . a lso ,  we n  Reference #> 21 J . a lso ,  ther  Reference"},{"path":"https://andreanini.github.io/idiolect/dev/articles/idiolect.html","id":"conclusions","dir":"Articles","previous_headings":"Analysis of QQ","what":"Conclusions","title":"idiolect","text":"Although score assigned QQ high, depending calibration data, can correspond various magnitudes LLRLLR. LLRLLR value QQ can also plotted onto TRUE vs. FALSE distributions using second argument density_plot(). q argument can used draw black vertical line crosses two distributions horizontal axis corresponding score QQ.  perform calibration calibrate_LLR() function used using validation results calibration data function returns LLRLLR value also verbal labels interpretation (Marquis et al. 2016). final conclusion analysis therefore following: similarity score QQ given KK 1, corresponds LLR=LLR= 1.122. similarity 13.24 times likely observed case HpH_p case HdH_d. Therefore, linguistic analysis offers Moderate support HpH_p. conclusion can complemented explanation implication results trier facts showing table posterior probabilities assuming range prior probabilities. can done posterior() function inserting input value LLRLLR table reveals , assuming prior probability HpH_p 0.00001 (roughly, one population Manchester), LLRLLR transform probability posterior probability HpH_p 0.000013. words, make much substantial difference trial. However, prior probability HpH_p 0.5, results turn 0.93, substantial change. table shows present evidence change probability HpH_p true equal higher 0.9 prior greater 0.4.","code":"density_plot(res, q = q.res$score) q.llr <- calibrate_LLR(res, q.res, latex = T) q.llr$`Verbal label` #> [1] \"Moderate support for $H_p$\" strwrap(q.llr$Interpretation) #> [1] \"The similarity is 13.24 times more likely to be observed in the case of\" #> [2] \"$H_p$ than in the case of $H_d$\" posterior(q.llr$LLR) |>    dplyr::select(prosecution_prior_probs, prosecution_post_probs) #> # A tibble: 11 × 2 #>    prosecution_prior_probs prosecution_post_probs #>                      <dbl>                  <dbl> #>  1                0.000001              0.0000132 #>  2                0.01                  0.118     #>  3                0.1                   0.595     #>  4                0.2                   0.768     #>  5                0.3                   0.850     #>  6                0.4                   0.898     #>  7                0.5                   0.930     #>  8                0.6                   0.952     #>  9                0.7                   0.969     #> 10                0.8                   0.981     #> 11                0.9                   0.992"},{"path":"https://andreanini.github.io/idiolect/dev/articles/idiolect.html","id":"acknowledgements","dir":"Articles","previous_headings":"","what":"Acknowledgements","title":"idiolect","text":"like thank Shunichi Ishihara Marie Bojsen-Møller helpful comments first draft vignette.","code":""},{"path":[]},{"path":"https://andreanini.github.io/idiolect/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Andrea Nini. Author, maintainer, copyright holder. David van Leeuwen. Copyright holder.           Author bundled functions package ROC","code":""},{"path":"https://andreanini.github.io/idiolect/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Andrea Nini (2024). Idiolect: R package forensic authorship analysis. https://andreanini.github.io/idiolect/.","code":"@Manual{,   title = {Idiolect: An R package for forensic authorship analysis},   author = {{Andrea Nini}},   year = {2024},   url = {https://andreanini.github.io/idiolect/}, }"},{"path":"https://andreanini.github.io/idiolect/dev/index.html","id":"idiolect-","dir":"","previous_headings":"","what":"Forensic Authorship Analysis","title":"Forensic Authorship Analysis","text":"idiolect R package designed provide comprehensive suite tools performing comparative authorship analysis within forensic context using Likelihood Ratio Framework (e.g. Ishihara 2021; Nini 2023). package contains set authorship analysis functions take set texts input output scores can calibrated likelihood ratios. package dependent quanteda (Benoit et al. 2018) Natural Language Processing functions.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Forensic Authorship Analysis","text":"can install idiolect CRAN:","code":"install.packages(\"idiolect\")"},{"path":"https://andreanini.github.io/idiolect/dev/index.html","id":"workflow","dir":"","previous_headings":"","what":"Workflow","title":"Forensic Authorship Analysis","text":"main functions contained package reflect typical workflow authorship analysis forensic problems: Input data using create_corpus(); Optionally mask content/topic texts using contentmask(); Launch analysis (e.g. delta(), ngram_tracing(), impostors()); Test performance method ground truth data using performance(); Finally, apply method questioned text generate likelihood ratio calibrate_LLR(). Check website vignette examples.","code":""},{"path":[]},{"path":"https://andreanini.github.io/idiolect/dev/reference/calibrate_LLR.html","id":null,"dir":"Reference","previous_headings":"","what":"Calibrate scores into Log-Likelihood Ratios — calibrate_LLR","title":"Calibrate scores into Log-Likelihood Ratios — calibrate_LLR","text":"function used transform scores returned authorship analysis functions Log-Likelihood Ratio (LLR).","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/calibrate_LLR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calibrate scores into Log-Likelihood Ratios — calibrate_LLR","text":"","code":"calibrate_LLR(calibration.dataset, dataset, latex = FALSE)"},{"path":"https://andreanini.github.io/idiolect/dev/reference/calibrate_LLR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calibrate scores into Log-Likelihood Ratios — calibrate_LLR","text":"calibration.dataset data frame containing calibration dataset, typically output authorship analysis function like impostors(). dataset data frame containing scores calibrated LLRs using calibration dataset. typically result applying function like impostors() Q texts. latex logical value. FALSE (default), hypothesis labels printed plain text (Hp/Hd). TRUE labels written read LaTeX ($H_p$/$H_d$).","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/calibrate_LLR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calibrate scores into Log-Likelihood Ratios — calibrate_LLR","text":"function returns data frame LLRs (base 10), well verbal label according Marquis et al (2016) verbal interpretation results.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/calibrate_LLR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calibrate scores into Log-Likelihood Ratios — calibrate_LLR","text":"Marquis, Raymond, Alex Biedermann, Liv Cadola, Christophe Champod, Line Gueissaz, Geneviève Massonnet, Williams David Mazzella, Franco Taroni & Tacha Hicks. 2016. Discussion implement verbal scale forensic laboratory: Benefits, pitfalls suggestions avoid misunderstandings. Science & Justice 56(5). 364–370. https://doi.org/10.1016/j.scijus.2016.05.009.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/calibrate_LLR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calibrate scores into Log-Likelihood Ratios — calibrate_LLR","text":"","code":"calib <- data.frame(score = c(0.5, 0.2, 0.8, 0.01, 0.6), target = c(TRUE, FALSE, TRUE, FALSE, TRUE)) q <- data.frame(score = c(0.6, 0.002)) calibrate_LLR(calib, q) #>   score     LLR                    Verbal label #> 1 0.600  16.135 Extremely strong support for Hp #> 2 0.002 -22.723 Extremely strong support for Hd #>                                                                                                     Interpretation #> 1    The similarity is 13645831365889294 times more likely to be observed in the case of Hp than in the case of Hd #> 2 The similarity is 5.28445251775179e+22 times more likely to be observed in the case of Hd than in the case of Hp"},{"path":"https://andreanini.github.io/idiolect/dev/reference/chunk_texts.html","id":null,"dir":"Reference","previous_headings":"","what":"Chunk a corpus — chunk_texts","title":"Chunk a corpus — chunk_texts","text":"function can used chunk corpus order control sample sizes.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/chunk_texts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Chunk a corpus — chunk_texts","text":"","code":"chunk_texts(corpus, size)"},{"path":"https://andreanini.github.io/idiolect/dev/reference/chunk_texts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Chunk a corpus — chunk_texts","text":"corpus quanteda corpus. size size chunks number tokens.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/chunk_texts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Chunk a corpus — chunk_texts","text":"quanteda corpus object text chunk size requested.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/chunk_texts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Chunk a corpus — chunk_texts","text":"","code":"corpus <- quanteda::corpus(c(\"The cat sat on the mat\", \"The dog sat on the chair\")) quanteda::docvars(corpus, \"author\") <- c(\"A\", \"B\") chunk_texts(corpus, size = 2) #> Corpus consisting of 6 documents and 1 docvar. #> text1.1 : #> \"The cat\" #>  #> text1.2 : #> \"sat on\" #>  #> text1.3 : #> \"the mat\" #>  #> text2.1 : #> \"The dog\" #>  #> text2.2 : #> \"sat on\" #>  #> text2.3 : #> \"the chair\" #>"},{"path":"https://andreanini.github.io/idiolect/dev/reference/concordance.html","id":null,"dir":"Reference","previous_headings":"","what":"Qualitative examination of evidence — concordance","title":"Qualitative examination of evidence — concordance","text":"function uses quanteda::kwic() return concordance search pattern. function takes input three datasets pattern returns data frame hits labelled authorship.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/concordance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Qualitative examination of evidence — concordance","text":"","code":"concordance(   q.data,   k.data,   reference.data,   search,   token.type = \"word\",   window = 5,   case_insensitive = TRUE )"},{"path":"https://andreanini.github.io/idiolect/dev/reference/concordance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Qualitative examination of evidence — concordance","text":"q.data quanteda corpus object, output create_corpus(), tokens object tokens sentences, output tokenize_sents(). k.data quanteda corpus object, output create_corpus(), tokens object tokens sentences, output tokenize_sents(). reference.data quanteda corpus object, output create_corpus(), tokens object tokens sentences, output tokenize_sents(). optional. search string. can sequence characters also accepts use * wildcard. special tokens sentence boundaries 'BOS' beginning sentence 'EOS' end sentence. token.type Choice \"word\" (default), searches word punctuation mark tokens, \"character\", instead uses single character search. window number context items displayed around keyword (quanteda::kwic() parameter). case_insensitive Logical; TRUE, ignore case (quanteda::kwic() parameter).","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/concordance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Qualitative examination of evidence — concordance","text":"function returns data frame containing concordances search pattern.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/concordance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Qualitative examination of evidence — concordance","text":"","code":"concordance(enron.sample[1], enron.sample[2], enron.sample[3], \"wants to\", token.type = \"word\") #>          docname from to     pre     node           post authorship #> 1 Kevin_h_Mail_1    5  6 N N N N wants to be N when he V          Q  #using wildcards concordance(enron.sample[1], enron.sample[2], enron.sample[3], \"wants * be\", token.type = \"word\") #>          docname from to     pre        node           post authorship #> 1 Kevin_h_Mail_1    5  7 N N N N wants to be N when he V up          Q  #searching character sequences with wildcards concordance(enron.sample[1], enron.sample[2], enron.sample[3], \"help*\", token.type = \"character\") #>          docname from   to   pre  node  post authorship #> 1 Kevin_h_Mail_1  703  707 need  help  V it           Q #> 2 Kevin_h_Mail_1 2014 2018 want  help  V it           Q #> 3 Kevin_h_Mail_3 1797 1801  N ,  helpe d the          K #> 4 Kevin_h_Mail_4   52   56  P P  helpe d the  Reference  #using sentences enron.sents <- tokens(enron.sample, \"sentence\") concordance(enron.sents[1], enron.sents[2], enron.sents[3], \". _EOS_\", token.type = \"word\") #>           docname from  to                       pre    node #> 1  Kevin_h_Mail_1  114 115               N , but V D . _EOS_ #> 2  Kevin_h_Mail_1  160 161            D N in first N . _EOS_ #> 3  Kevin_h_Mail_1  189 190             N about a N N . _EOS_ #> 4  Kevin_h_Mail_1  369 370             and we V to V . _EOS_ #> 5  Kevin_h_Mail_1  409 410           ' re V with her . _EOS_ #> 6  Kevin_h_Mail_1  545 546            the N of the N . _EOS_ #> 7  Kevin_h_Mail_1  698 699  V in you getting neither . _EOS_ #> 8  Kevin_h_Mail_1  713 714       just the N it works . _EOS_ #> 9  Kevin_h_Mail_1  735 736                N is a J N . _EOS_ #> 10 Kevin_h_Mail_1  873 874      have to say during N . _EOS_ #> 11 Kevin_h_Mail_3  173 174                J as a J N . _EOS_ #> 12 Kevin_h_Mail_3  235 236       get V into the call . _EOS_ #> 13 Kevin_h_Mail_3  285 286      , please let me know . _EOS_ #> 14 Kevin_h_Mail_3  341 342            you who V of N . _EOS_ #> 15 Kevin_h_Mail_3  366 367               B for a N N . _EOS_ #> 16 Kevin_h_Mail_3  410 411     P went well last week . _EOS_ #> 17 Kevin_h_Mail_3  560 561             of N in its N . _EOS_ #> 18 Kevin_h_Mail_3  599 600             for the B J N . _EOS_ #> 19 Kevin_h_Mail_3  625 626               N N and N N . _EOS_ #> 20 Kevin_h_Mail_3  715 716                 N J J J N . _EOS_ #> 21 Kevin_h_Mail_4  222 223            , and V your N . _EOS_ #> 22 Kevin_h_Mail_4  302 303            J N with the N . _EOS_ #> 23 Kevin_h_Mail_4  666 667             V for a few N . _EOS_ #> 24 Kevin_h_Mail_4  716 717 especially on the first N . _EOS_ #> 25 Kevin_h_Mail_4  754 755             her to N on N . _EOS_ #> 26 Kevin_h_Mail_4  774 775         after the N has V . _EOS_ #> 27 Kevin_h_Mail_4  785 786             to N on the N . _EOS_ #>                       post authorship #> 1        _BOS_ P V us they          Q #> 2        _BOS_ N is in the          Q #> 3           _BOS_ P , V is          Q #> 4      _BOS_ J N is always          Q #> 5            _BOS_ P , P ,          Q #> 6         _BOS_ N is not a          Q #> 7          _BOS_ J N , but          Q #> 8     _BOS_ P is what your          Q #> 9          _BOS_ J N are B          Q #> 10                                  Q #> 11 _BOS_ P had already run          K #> 12      _BOS_ V the N from          K #> 13      _BOS_ P i am still          K #> 14           _BOS_ P P P N          K #> 15       _BOS_ P per our N          K #> 16         _BOS_ P V to me          K #> 17        _BOS_ N of the N          K #> 18          _BOS_ P P , in          K #> 19           _BOS_ P P V a          K #> 20                                  K #> 21        _BOS_ N , over J  Reference #> 22          _BOS_ B to D i  Reference #> 23     _BOS_ N and N under  Reference #> 24      _BOS_ V , with her  Reference #> 25     _BOS_ V N should be  Reference #> 26 _BOS_ V from talking to  Reference #> 27                          Reference"},{"path":"https://andreanini.github.io/idiolect/dev/reference/contentmask.html","id":null,"dir":"Reference","previous_headings":"","what":"Content masking — contentmask","title":"Content masking — contentmask","text":"function offers three algorithms topic/content masking. order run masking algorithms, spacy tokenizer POS-tagger run first (via spacyr). information masking algorithms see Details .","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/contentmask.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Content masking — contentmask","text":"","code":"contentmask(   corpus,   model = \"en_core_web_sm\",   algorithm = \"POSnoise\",   fw_list = \"eng_halvani\",   replace_non_ascii = TRUE )"},{"path":"https://andreanini.github.io/idiolect/dev/reference/contentmask.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Content masking — contentmask","text":"corpus quanteda corpus object, typically output create_corpus() function. model spacy model use. default \"en_core_web_sm\". algorithm string, either \"POSnoise\" (default), \"frames\", \"textdistortion\". fw_list list function words use textdistortion algorithm. either default (\"eng_halvani\") list function words used POSnoise can vector strings string function word keep. replace_non_ascii logical value indicating whether remove non-ASCII characters (including emojis). default.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/contentmask.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Content masking — contentmask","text":"quanteda corpus object containing functional tokens, depending algorithm chosen. corpus contains docvars input. Email addresses URLs treated like nouns.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/contentmask.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Content masking — contentmask","text":"default algorithm content masking function applies POSnoise (Halvani Graner 2021). algorithm works English transforms text masking tokens using POS tag tokens : nouns, verbs, adjectives, adverbs, digits, symbols leaving rest unchanged. POSnoise uses list function words English also includes frequent words belonging masked Part Speech tags tend mostly functional (e.g. make, recently, well). Another algorithm implemented Nini's (2023) frames frame n-grams. algorithm involve special list tokens therefore can potentially work language provided correct spacy model loaded. algorithm consists masking tokens using POS tag nouns, verbs, personal pronouns. Finally, last algorithm implemented version textdistortion, originally proposed Stamatatos (2017). version algorithm essentially POSnoise without POS tag information. default implementation uses list function words used POSnoise. addition function words provided, function treats punctuation marks new line breaks function words keep. basic tokenization done using spacyr right model language analysed selected. never used spacyr please follow instructions set install model using function : https://spacyr.quanteda.io. removal non-ASCII characters done using textclean package.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/contentmask.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Content masking — contentmask","text":"Halvani, Oren & Lukas Graner. 2021. POSNoise: Effective Countermeasure Topic Biases Authorship Analysis. Proceedings 16th International Conference Availability, Reliability Security, 1–12. Vienna, Austria: Association Computing Machinery. https://doi.org/10.1145/3465481.3470050. Nini, Andrea. 2023. Theory Linguistic Individuality Authorship Analysis (Elements Forensic Linguistics). Cambridge, UK: Cambridge University Press. Stamatatos, Efstathios. 2017. Masking topic-related information enhance authorship attribution. Journal Association Information Science Technology. https://doi.org/10.1002/asi.23968.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/contentmask.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Content masking — contentmask","text":"","code":"if (FALSE) { # \\dontrun{ text <- \"The cat was on the chair. He didn't move\\ncat@pets.com;\\nhttp://quanteda.io/. i.e. a test \" toy.corpus <- quanteda::corpus(text) contentmask(toy.corpus, algorithm = \"POSnoise\") contentmask(toy.corpus, algorithm = \"textdistortion\") } # }"},{"path":"https://andreanini.github.io/idiolect/dev/reference/create_corpus.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a corpus — create_corpus","title":"Create a corpus — create_corpus","text":"Function read text data turn quanteda corpus object.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/create_corpus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a corpus — create_corpus","text":"","code":"create_corpus(path)"},{"path":"https://andreanini.github.io/idiolect/dev/reference/create_corpus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a corpus — create_corpus","text":"path string containing path folder plain text files (ending .txt) name structured following: authorname_textname.txt (e.g. smith_text1.txt).","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/create_corpus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a corpus — create_corpus","text":"quanteda corpus object authors' names text names docvars.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/create_corpus.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a corpus — create_corpus","text":"","code":"if (FALSE) { # \\dontrun{ path <- \"path/to/data\" create_corpus(path) } # }"},{"path":"https://andreanini.github.io/idiolect/dev/reference/delta.html","id":null,"dir":"Reference","previous_headings":"","what":"Delta — delta","title":"Delta — delta","text":"function runs Cosine Delta analysis (Smith Aldridge 2011; Evert et al. 2017).","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/delta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delta — delta","text":"","code":"delta(   q.data,   k.data,   tokens = \"word\",   remove_punct = FALSE,   remove_symbols = TRUE,   remove_numbers = TRUE,   lowercase = TRUE,   n = 1,   trim = TRUE,   threshold = 150,   features = FALSE,   cores = NULL )"},{"path":"https://andreanini.github.io/idiolect/dev/reference/delta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delta — delta","text":"q.data questioned disputed data, either corpus (output create_corpus()) quanteda dfm (output vectorize()). k.data known undisputed data, either corpus (output create_corpus()) quanteda dfm (output vectorize()). tokens type tokens extract, either \"word\" (default) \"character\". remove_punct logical value. FALSE (default) keeps punctuation marks. remove_symbols logical value. TRUE (default) removes symbols. remove_numbers logical value. TRUE (default) removes numbers lowercase logical value. TRUE (default) transforms tokens lower case. n order size n-grams extracted. Default 1. trim logical value. TRUE (default) frequent tokens kept. threshold numeric value indicating many frequent tokens keep trim = TRUE. default 150. features Logical default FALSE. TRUE, output contain features used. cores number cores use parallel processing (default one).","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/delta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Delta — delta","text":"features set FALSE output data frame containing results comparisons Q texts K texts. features set TRUE output list containing results data frame vector features used analysis.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/delta.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Delta — delta","text":"Evert, Stefan, Thomas Proisl, Fotis Jannidis, Isabella Reger, Steffen Pielström, Christof Schöch & Thorsten Vitt. 2017. Understanding explaining Delta measures authorship attribution. Digital Scholarship Humanities 32. ii4–ii16. https://doi.org/10.1093/llc/fqx023. Smith, Peter W H & W Aldridge. 2011. Improving Authorship Attribution: Optimizing Burrows’ Delta Method*. Journal Quantitative Linguistics 18(1). 63–88. https://doi.org/10.1080/09296174.2011.533591.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/delta.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Delta — delta","text":"","code":"Q <- enron.sample[c(5:6)] K <- enron.sample[-c(5:6)] delta(Q, K) #>                    Q                 K target  score #> 1     Kevin_h_Mail_2    Kevin_h_Mail_1   TRUE -0.039 #> 2  Kimberly_w_Mail_3    Kevin_h_Mail_1  FALSE -0.061 #> 3     Kevin_h_Mail_2    Kevin_h_Mail_3   TRUE  0.177 #> 4  Kimberly_w_Mail_3    Kevin_h_Mail_3  FALSE  0.075 #> 5     Kevin_h_Mail_2    Kevin_h_Mail_4   TRUE -0.068 #> 6  Kimberly_w_Mail_3    Kevin_h_Mail_4  FALSE -0.078 #> 7     Kevin_h_Mail_2    Kevin_h_Mail_5   TRUE -0.018 #> 8  Kimberly_w_Mail_3    Kevin_h_Mail_5  FALSE -0.161 #> 9     Kevin_h_Mail_2 Kimberly_w_Mail_1  FALSE -0.144 #> 10 Kimberly_w_Mail_3 Kimberly_w_Mail_1   TRUE  0.110 #> 11    Kevin_h_Mail_2 Kimberly_w_Mail_2  FALSE -0.091 #> 12 Kimberly_w_Mail_3 Kimberly_w_Mail_2   TRUE  0.195 #> 13    Kevin_h_Mail_2 Kimberly_w_Mail_4  FALSE -0.072 #> 14 Kimberly_w_Mail_3 Kimberly_w_Mail_4   TRUE  0.315 #> 15    Kevin_h_Mail_2 Kimberly_w_Mail_5  FALSE -0.113 #> 16 Kimberly_w_Mail_3 Kimberly_w_Mail_5   TRUE  0.243 #> 17    Kevin_h_Mail_2    Larry_c_Mail_1  FALSE  0.177 #> 18 Kimberly_w_Mail_3    Larry_c_Mail_1  FALSE -0.073 #> 19    Kevin_h_Mail_2    Larry_c_Mail_2  FALSE -0.084 #> 20 Kimberly_w_Mail_3    Larry_c_Mail_2  FALSE -0.192 #> 21    Kevin_h_Mail_2    Larry_c_Mail_3  FALSE -0.059 #> 22 Kimberly_w_Mail_3    Larry_c_Mail_3  FALSE -0.009 #> 23    Kevin_h_Mail_2    Larry_c_Mail_4  FALSE  0.073 #> 24 Kimberly_w_Mail_3    Larry_c_Mail_4  FALSE  0.028 #> 25    Kevin_h_Mail_2    Larry_c_Mail_5  FALSE  0.087 #> 26 Kimberly_w_Mail_3    Larry_c_Mail_5  FALSE -0.172 #> 27    Kevin_h_Mail_2    Lindy_d_Mail_4  FALSE  0.017 #> 28 Kimberly_w_Mail_3    Lindy_d_Mail_4  FALSE -0.021 #> 29    Kevin_h_Mail_2    Lindy_d_Mail_1  FALSE -0.155 #> 30 Kimberly_w_Mail_3    Lindy_d_Mail_1  FALSE  0.082 #> 31    Kevin_h_Mail_2    Lindy_d_Mail_2  FALSE -0.046 #> 32 Kimberly_w_Mail_3    Lindy_d_Mail_2  FALSE -0.086 #> 33    Kevin_h_Mail_2    Lindy_d_Mail_3  FALSE -0.168 #> 34 Kimberly_w_Mail_3    Lindy_d_Mail_3  FALSE -0.084 #> 35    Kevin_h_Mail_2    Lindy_d_Mail_5  FALSE -0.018 #> 36 Kimberly_w_Mail_3    Lindy_d_Mail_5  FALSE  0.032 #> 37    Kevin_h_Mail_2      Liz_t_Mail_2  FALSE  0.032 #> 38 Kimberly_w_Mail_3      Liz_t_Mail_2  FALSE -0.143 #> 39    Kevin_h_Mail_2      Liz_t_Mail_1  FALSE  0.113 #> 40 Kimberly_w_Mail_3      Liz_t_Mail_1  FALSE  0.116 #> 41    Kevin_h_Mail_2      Liz_t_Mail_3  FALSE  0.139 #> 42 Kimberly_w_Mail_3      Liz_t_Mail_3  FALSE  0.080 #> 43    Kevin_h_Mail_2      Liz_t_Mail_4  FALSE  0.145 #> 44 Kimberly_w_Mail_3      Liz_t_Mail_4  FALSE -0.032 #> 45    Kevin_h_Mail_2   Louise_k_Mail_4  FALSE  0.030 #> 46 Kimberly_w_Mail_3   Louise_k_Mail_4  FALSE -0.154 #> 47    Kevin_h_Mail_2   Louise_k_Mail_1  FALSE -0.038 #> 48 Kimberly_w_Mail_3   Louise_k_Mail_1  FALSE -0.012 #> 49    Kevin_h_Mail_2   Louise_k_Mail_2  FALSE -0.065 #> 50 Kimberly_w_Mail_3   Louise_k_Mail_2  FALSE -0.104 #> 51    Kevin_h_Mail_2   Louise_k_Mail_3  FALSE  0.152 #> 52 Kimberly_w_Mail_3   Louise_k_Mail_3  FALSE -0.002 #> 53    Kevin_h_Mail_2   Louise_k_Mail_5  FALSE -0.008 #> 54 Kimberly_w_Mail_3   Louise_k_Mail_5  FALSE -0.060 #> 55    Kevin_h_Mail_2     Lynn_b_Mail_3  FALSE -0.203 #> 56 Kimberly_w_Mail_3     Lynn_b_Mail_3  FALSE  0.072 #> 57    Kevin_h_Mail_2     Lynn_b_Mail_1  FALSE -0.111 #> 58 Kimberly_w_Mail_3     Lynn_b_Mail_1  FALSE  0.114 #> 59    Kevin_h_Mail_2     Lynn_b_Mail_2  FALSE -0.094 #> 60 Kimberly_w_Mail_3     Lynn_b_Mail_2  FALSE  0.052 #> 61    Kevin_h_Mail_2     Lynn_b_Mail_4  FALSE  0.042 #> 62 Kimberly_w_Mail_3     Lynn_b_Mail_4  FALSE  0.132 #> 63    Kevin_h_Mail_2     Lynn_b_Mail_5  FALSE -0.106 #> 64 Kimberly_w_Mail_3     Lynn_b_Mail_5  FALSE -0.070 #> 65    Kevin_h_Mail_2     Lysa_a_Mail_3  FALSE -0.006 #> 66 Kimberly_w_Mail_3     Lysa_a_Mail_3  FALSE -0.278 #> 67    Kevin_h_Mail_2     Lysa_a_Mail_1  FALSE -0.004 #> 68 Kimberly_w_Mail_3     Lysa_a_Mail_1  FALSE -0.193 #> 69    Kevin_h_Mail_2     Lysa_a_Mail_2  FALSE -0.044 #> 70 Kimberly_w_Mail_3     Lysa_a_Mail_2  FALSE -0.134 #> 71    Kevin_h_Mail_2     Lysa_a_Mail_4  FALSE  0.137 #> 72 Kimberly_w_Mail_3     Lysa_a_Mail_4  FALSE -0.270 #> 73    Kevin_h_Mail_2     Lysa_a_Mail_5  FALSE  0.081 #> 74 Kimberly_w_Mail_3     Lysa_a_Mail_5  FALSE -0.220 #> 75    Kevin_h_Mail_2        M_f_Mail_1  FALSE -0.242 #> 76 Kimberly_w_Mail_3        M_f_Mail_1  FALSE  0.024 #> 77    Kevin_h_Mail_2        M_f_Mail_2  FALSE -0.096 #> 78 Kimberly_w_Mail_3        M_f_Mail_2  FALSE -0.023 #> 79    Kevin_h_Mail_2        M_f_Mail_3  FALSE  0.123 #> 80 Kimberly_w_Mail_3        M_f_Mail_3  FALSE -0.017 #> 81    Kevin_h_Mail_2        M_f_Mail_4  FALSE -0.148 #> 82 Kimberly_w_Mail_3        M_f_Mail_4  FALSE  0.057 #> 83    Kevin_h_Mail_2        M_f_Mail_5  FALSE  0.058 #> 84 Kimberly_w_Mail_3        M_f_Mail_5  FALSE -0.135 #> 85    Kevin_h_Mail_2        M_l_Mail_3  FALSE -0.214 #> 86 Kimberly_w_Mail_3        M_l_Mail_3  FALSE  0.053 #> 87    Kevin_h_Mail_2        M_l_Mail_1  FALSE  0.009 #> 88 Kimberly_w_Mail_3        M_l_Mail_1  FALSE  0.051 #> 89    Kevin_h_Mail_2        M_l_Mail_2  FALSE -0.143 #> 90 Kimberly_w_Mail_3        M_l_Mail_2  FALSE -0.046 #> 91    Kevin_h_Mail_2        M_l_Mail_4  FALSE  0.024 #> 92 Kimberly_w_Mail_3        M_l_Mail_4  FALSE -0.032 #> 93    Kevin_h_Mail_2        M_l_Mail_5  FALSE  0.036 #> 94 Kimberly_w_Mail_3        M_l_Mail_5  FALSE  0.064"},{"path":"https://andreanini.github.io/idiolect/dev/reference/density_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot density of TRUE/FALSE distributions — density_plot","title":"Plot density of TRUE/FALSE distributions — density_plot","text":"Plot density TRUE/FALSE distributions","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/density_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot density of TRUE/FALSE distributions — density_plot","text":"","code":"density_plot(dataset, q = NULL)"},{"path":"https://andreanini.github.io/idiolect/dev/reference/density_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot density of TRUE/FALSE distributions — density_plot","text":"dataset data frame containing calibration dataset, typically output authorship analysis function like impostors(). q optional argument one value vector values contain score disputed text(s). plotted lines crossing density distributions.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/density_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot density of TRUE/FALSE distributions — density_plot","text":"ggplot2 plot density distributions scores TRUE (typically, '-author') vs. FALSE (typically, 'different-author').","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/density_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot density of TRUE/FALSE distributions — density_plot","text":"","code":"res <- data.frame(score = c(0.5, 0.2, 0.8, 0.01, 0.6), target = c(TRUE, FALSE, TRUE, FALSE, TRUE)) q <- c(0.11, 0.7) density_plot(res, q)"},{"path":"https://andreanini.github.io/idiolect/dev/reference/enron.sample.html","id":null,"dir":"Reference","previous_headings":"","what":"Enron sample — enron.sample","title":"Enron sample — enron.sample","text":"small sample Enron corpus comprising ten authors approximately amount data. data pre-processed using POSnoise algorithm mask content (see contentmask()).","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/enron.sample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Enron sample — enron.sample","text":"","code":"enron.sample"},{"path":"https://andreanini.github.io/idiolect/dev/reference/enron.sample.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Enron sample — enron.sample","text":"quanteda corpus object.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/enron.sample.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Enron sample — enron.sample","text":"Halvani, Oren. 2021. Practice-Oriented Authorship Verification. Technical University Darmstadt PhD Thesis. https://tuprints.ulb.tu-darmstadt.de/19861/","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/impostors.html","id":null,"dir":"Reference","previous_headings":"","what":"Impostors Method — impostors","title":"Impostors Method — impostors","text":"function runs Impostors Method authorship verification. Impostors Method based calculating similarity score , using corpus impostor texts, perform bootstrapping analysis sampling random subsets features impostors order test robustness similarity.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/impostors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Impostors Method — impostors","text":"","code":"impostors(   q.data,   k.data,   cand.imps,   algorithm = \"RBI\",   coefficient = \"minmax\",   k = 300,   m = 100,   n = 25,   features = FALSE,   cores = NULL )"},{"path":"https://andreanini.github.io/idiolect/dev/reference/impostors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Impostors Method — impostors","text":"q.data questioned disputed data, either corpus (output create_corpus()) quanteda dfm (output vectorize()). k.data known undisputed data, either corpus (output create_corpus()) quanteda dfm (output vectorize()). one sample candidate author accepted algorithms except IM. cand.imps impostors data candidate authors, either corpus (output create_corpus()) quanteda dfm (output vectorize()). can object k.data (e.g. recycle impostors). algorithm string specifying impostors algorithm use, either \"RBI\" (deafult), \"KGI\", \"IM\". coefficient string indicating coefficient use, either \"minmax\" (default) \"cosine\". apply algorithm KGI, distance \"minmax\". k k parameters RBI algorithm. used algorithms. default 300. m m parameter IM algorithm. used algorithms. default 100. n n parameter IM algorithm. used algorithms. default 25. features logical value indicating whether important features retrieved . default FALSE. applies RBI algorithm. cores number cores use parallel processing (default one).","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/impostors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Impostors Method — impostors","text":"function test possible combinations Q texts candidate authors return data frame containing score ranging 0 1, higher score indicating higher likelihood author produced two sets texts. data frame contains column called \"target\" logical value TRUE author Q text candidate FALSE otherwise. RBI algorithm selected features parameter TRUE data frame also contain column features likely impact score. features consistently found shared candidate author's data questioned data also tend rare dataset impostors.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/impostors.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Impostors Method — impostors","text":"several variants Impostors Method function can run three : IM: original Impostors Method proposed Koppel Winter (2014). KGI: Kestemont's et al. (2016) version, popular implementation Impostors Method stylometry. inspired IM generalized version, General Impostors Method proposed Seidman (2013). RBI: Rank-Based Impostors Method (Potha Stamatatos 2017, 2020), default option recent tends outperform original. two data sets q.data, k.data, must disjunct terms texts contain otherwise error returned. However, cand.imps k.data can object, example, use candidates' texts impostors. function always exclude impostor texts author Q K texts considered.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/impostors.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Impostors Method — impostors","text":"Kestemont, Mike, Justin Stover, Moshe Koppel, Folgert Karsdorp & Walter Daelemans. 2016. Authenticating writings Julius Caesar. Expert Systems Applications 63. 86–96. https://doi.org/10.1016/j.eswa.2016.06.029. Koppel, Moshe & Yaron Winter. 2014. Determining two documents written author. Journal Association Information Science Technology 65(1). 178–187. Potha, Nektaria & Efstathios Stamatatos. 2017. Improved Impostors Method Authorship Verification. Gareth J.FALSE. Jones, Séamus Lawless, Julio Gonzalo, Liadh Kelly, Lorraine Goeuriot, Thomas Mandl, Linda Cappellato & Nicola Ferro (eds.), Experimental IR Meets Multilinguality, Multimodality, Interaction (Lecture Notes Computer Science), vol. 10456, 138–144. Springer, Cham. https://doi.org/10.1007/978-3-319-65813-1_14. (5 September, 2017). Potha, Nektaria & Efstathios Stamatatos. 2020. Improved algorithms extrinsic author verification. Knowledge Information Systems 62(5). 1903–1921. https://doi.org/10.1007/s10115-019-01408-4. Seidman, Shachar. 2013. Authorship Verification Using Impostors Method. Pamela Forner, Roberto Navigli, Dan Tufis & Nicola Ferro (eds.), Proceedings CLEF 2013 Evaluation Labs Workshop – Working Notes Papers, 23–26. Valencia, Spain. https://ceur-ws.org/Vol-1179/.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/impostors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Impostors Method — impostors","text":"","code":"Q <- enron.sample[1] K <- enron.sample[2:3] imps <- enron.sample[4:9] impostors(Q, K, imps, algorithm = \"KGI\") #>         K              Q target score #> 1 Kevin_h Kevin_h_Mail_1   TRUE  0.36"},{"path":"https://andreanini.github.io/idiolect/dev/reference/lambdaG.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply the LambdaG algorithm — lambdaG","title":"Apply the LambdaG algorithm — lambdaG","text":"function calculates likelihood ratio grammar models, \\(\\lambda_G\\), Nini et al. (review). order run analysis paper, data must preprocessed using contentmask() \"algorithm\" parameter set \"POSnoise\".","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/lambdaG.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply the LambdaG algorithm — lambdaG","text":"","code":"lambdaG(q.data, k.data, ref.data, N = 10, r = 30, cores = NULL)"},{"path":"https://andreanini.github.io/idiolect/dev/reference/lambdaG.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply the LambdaG algorithm — lambdaG","text":"q.data questioned disputed data quanteda tokens object tokens sentences (e.g. output tokenize_sents()). k.data known undisputed data quanteda tokens object tokens sentences (e.g. output tokenize_sents()). ref.data reference dataset quanteda tokens object tokens sentences (e.g. output tokenize_sents()). can object k.data. N order model. Default 10. r number iterations. Default 30. cores number cores use parallel processing (default one).","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/lambdaG.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply the LambdaG algorithm — lambdaG","text":"function test possible combinations Q texts candidate authors return data frame containing \\(\\lambda_G\\), uncalibrated log-likelihood ratio (base 10). \\(\\lambda_G\\) can calibrated likelihood ratio expresses strength evidence using calibrate_LLR(). data frame contains column called \"target\" logical value TRUE author Q text candidate FALSE otherwise.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/lambdaG.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Apply the LambdaG algorithm — lambdaG","text":"Nini, ., Halvani, O., Graner, L., Gherardi, V., Ishihara, S. Authorship Verification based Likelihood Ratio Grammar Models. https://arxiv.org/abs/2403.08462v1","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/lambdaG.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply the LambdaG algorithm — lambdaG","text":"","code":"q.data <- enron.sample[1] |> quanteda::tokens(\"sentence\") k.data <- enron.sample[2:10] |> quanteda::tokens(\"sentence\") ref.data <- enron.sample[11:ndoc(enron.sample)] |> quanteda::tokens(\"sentence\") lambdaG(q.data, k.data, ref.data) #>            K              Q target  score #> 1    Kevin_h Kevin_h_Mail_1   TRUE 37.171 #> 2 Kimberly_w Kevin_h_Mail_1  FALSE -6.720"},{"path":"https://andreanini.github.io/idiolect/dev/reference/lambdaG_visualize.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize the output of the LambdaG algorithm — lambdaG_visualize","title":"Visualize the output of the LambdaG algorithm — lambdaG_visualize","text":"function outputs colour-coded list sentences belonging input Q text ordered highest lowest \\(\\lambda_G\\), shown Nini et al. (review).","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/lambdaG_visualize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize the output of the LambdaG algorithm — lambdaG_visualize","text":"","code":"lambdaG_visualize(   q.data,   k.data,   ref.data,   N = 10,   r = 30,   output = \"html\",   print = \"\",   scale = \"absolute\",   negative = FALSE,   order.by = \"importance\",   cores = NULL )"},{"path":"https://andreanini.github.io/idiolect/dev/reference/lambdaG_visualize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize the output of the LambdaG algorithm — lambdaG_visualize","text":"q.data single questioned disputed text quanteda tokens object tokens sentences (e.g. output tokenize_sents()). k.data known undisputed corpus containing exclusively single candidate author's texts quanteda tokens object tokens sentences (e.g. output tokenize_sents()). ref.data reference dataset quanteda tokens object tokens sentences (e.g. output tokenize_sents()). N order model. Default 10. r number iterations. Default 30. output string detailing file type colour-coded text output. Either \"html\" (default) \"latex\". print string indicating path filename save colour-coded text file. left empty (default), nothing printed. scale string indicating scale use colour-code text file. \"absolute\" (default) raw \\(\\lambda_G\\) used; \"relative\", z-score \\(\\lambda_G\\) Q data used instead, thus showing relative importance. negative Logical. TRUE negative values \\(\\lambda_G\\) color-coded blue, otherwise (default) positive values \\(\\lambda_G\\) displayed red. applies HTML output. order.string indicating order output. \"importance\" (default) output ordered sentence \\(\\lambda_G\\) descending order, otherwise text displayed ordered appears. cores number cores use parallel processing (default one).","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/lambdaG_visualize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize the output of the LambdaG algorithm — lambdaG_visualize","text":"function outputs list two objects: data frame row token Q text values \\(\\lambda_G\\) token sentences, decreasing order sentence \\(\\lambda_G\\) relative contribution token sentence final \\(\\lambda_G\\) percentage; raw code html LaTeX generates colour-coded file. path provided print argument function also save colour-coded text html plain text file.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/lambdaG_visualize.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Visualize the output of the LambdaG algorithm — lambdaG_visualize","text":"Nini, ., Halvani, O., Graner, L., Gherardi, V., Ishihara, S. Authorship Verification based Likelihood Ratio Grammar Models. https://arxiv.org/abs/2403.08462v1","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/lambdaG_visualize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize the output of the LambdaG algorithm — lambdaG_visualize","text":"","code":"q.data <- corpus_trim(enron.sample[1], \"sentences\", max_ntoken = 10) |> quanteda::tokens(\"sentence\") k.data <- enron.sample[2:5]|> quanteda::tokens(\"sentence\") ref.data <- enron.sample[6:ndoc(enron.sample)] |> quanteda::tokens(\"sentence\") outputs <- lambdaG_visualize(q.data, k.data, ref.data, r = 2) outputs$table #> # A tibble: 13 × 8 #>    sentence_id token_id t          lambdaG sentence_lambdaG zlambdaG #>          <int>    <int> <chr>        <dbl>            <dbl>    <dbl> #>  1           1        1 J          0.00220            0.311   -0.055 #>  2           1        2 N          0.0641             0.311    0.102 #>  3           1        3 ,         -0.748              0.311   -1.96  #>  4           1        4 but        0.430              0.311    1.03  #>  5           1        5 that      -0.120              0.311   -0.365 #>  6           1        6 's         1.02               0.311    2.53  #>  7           1        7 just      -0.0203             0.311   -0.112 #>  8           1        8 the        0.0379             0.311    0.035 #>  9           1        9 N          0.0181             0.311   -0.015 #> 10           1       10 it        -0.236              0.311   -0.658 #> 11           1       11 works     -0.0908             0.311   -0.291 #> 12           1       12 .          0.0214             0.311   -0.006 #> 13           1       13 ___EOS___ -0.0696             0.311   -0.237 #> # ℹ 2 more variables: token_contribution <dbl>, sent_contribution <dbl>"},{"path":"https://andreanini.github.io/idiolect/dev/reference/most_similar.html","id":null,"dir":"Reference","previous_headings":"","what":"Select the most similar texts to a specific text — most_similar","title":"Select the most similar texts to a specific text — most_similar","text":"Select similar texts specific text","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/most_similar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select the most similar texts to a specific text — most_similar","text":"","code":"most_similar(sample, pool, coefficient, n)"},{"path":"https://andreanini.github.io/idiolect/dev/reference/most_similar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select the most similar texts to a specific text — most_similar","text":"sample single row quanteda dfm representing sample match. pool dfm containing possible samples select top n. coefficient coefficient use similarity. Either \"minmax\", \"cosine\", \"Phi\". n number rows extract pool potential samples.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/most_similar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select the most similar texts to a specific text — most_similar","text":"function returns dfm containing top n similar rows input sample using minmax distance.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/most_similar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select the most similar texts to a specific text — most_similar","text":"","code":"text1 <- \"The cat sat on the mat\" text2 <- \"The dog sat on the chair\" text3 <- \"Violence is the last refuge of the incompetent\" c <- quanteda::corpus(c(text1, text2, text3)) d <- quanteda::tokens(c) |> quanteda::dfm() |> quanteda::dfm_weight(scheme = \"prop\") most_similar(d[1,], d[-1,], coefficient = \"minmax\", n = 1) #> Document-feature matrix of: 1 document, 13 features (61.54% sparse) and 0 docvars. #>        features #> docs          the cat       sat        on mat       dog     chair violence is #>   text2 0.3333333   0 0.1666667 0.1666667   0 0.1666667 0.1666667        0  0 #>        features #> docs    last #>   text2    0 #> [ reached max_nfeat ... 3 more features ]"},{"path":"https://andreanini.github.io/idiolect/dev/reference/ngram_tracing.html","id":null,"dir":"Reference","previous_headings":"","what":"N-gram tracing — ngram_tracing","title":"N-gram tracing — ngram_tracing","text":"function runs authorship analysis method called n-gram tracing, can used attribution verification.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/ngram_tracing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"N-gram tracing — ngram_tracing","text":"","code":"ngram_tracing(   q.data,   k.data,   tokens = \"character\",   remove_punct = FALSE,   remove_symbols = TRUE,   remove_numbers = TRUE,   lowercase = TRUE,   n = 9,   coefficient = \"simpson\",   features = FALSE,   cores = NULL )"},{"path":"https://andreanini.github.io/idiolect/dev/reference/ngram_tracing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"N-gram tracing — ngram_tracing","text":"q.data questioned disputed data, either corpus (output create_corpus()) quanteda dfm (output vectorize()). k.data known undisputed data, either corpus (output create_corpus()) quanteda dfm (output vectorize()). one sample candidate author accepted function combine make profile. tokens type tokens extract, either \"word\" \"character\" (default). remove_punct logical value. FALSE (default) keeps punctuation marks. remove_symbols logical value. TRUE (default) removes symbols. remove_numbers logical value. TRUE (default) removes numbers. lowercase logical value. TRUE (default) transforms tokens lower case. n order size n-grams extracted. Default 9. coefficient coefficient use compare texts, one : \"simpson\" (default), \"phi\", \"jaccard\", \"kulczynski\", \"cole\". features Logical default FALSE. TRUE result table contain features overlap unique overlap corpus. two texts present return n-grams common. cores number cores use parallel processing (default one).","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/ngram_tracing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"N-gram tracing — ngram_tracing","text":"function test possible combinations Q texts candidate authors return data frame containing value similarity coefficient selected called 'score' optional column overlapping features occur Q candidate considered Qs (ordered length n-gram variable length). data frame contains column called 'target' logical value TRUE author Q text candidate FALSE otherwise.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/ngram_tracing.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"N-gram tracing — ngram_tracing","text":"N-gram tracing originally proposed Grieve et al (2019). Nini (2023) proposed mathematical reinterpretation compatible Cognitive Linguistic theories language processing. tested several variants method found original version, uses Simpson's coefficient, tends outperformed versions using Phi coefficient, Kulczynski's coefficient, Cole coefficient. function can run n-gram tracing method using coefficients plus Jaccard coefficient reference, coefficient applied several forensic linguistic studies.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/ngram_tracing.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"N-gram tracing — ngram_tracing","text":"Grieve, Jack, Emily Chiang, Isobelle Clarke, Hannah Gideon, Aninna Heini, Andrea Nini & Emily Waibel. 2019. Attributing Bixby Letter using n-gram tracing. Digital Scholarship Humanities 34(3). 493–512. Nini, Andrea. 2023. Theory Linguistic Individuality Authorship Analysis (Elements Forensic Linguistics). Cambridge, UK: Cambridge University Press.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/ngram_tracing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"N-gram tracing — ngram_tracing","text":"","code":"Q <- enron.sample[c(5:6)] K <- enron.sample[-c(5:6)] ngram_tracing(Q, K, coefficient = 'phi') #>                    Q          K target  score #> 1     Kevin_h_Mail_2    Kevin_h   TRUE  0.032 #> 2  Kimberly_w_Mail_3    Kevin_h  FALSE  0.030 #> 3     Kevin_h_Mail_2 Kimberly_w  FALSE  0.031 #> 4  Kimberly_w_Mail_3 Kimberly_w   TRUE  0.086 #> 5     Kevin_h_Mail_2    Larry_c  FALSE  0.028 #> 6  Kimberly_w_Mail_3    Larry_c  FALSE  0.027 #> 7     Kevin_h_Mail_2    Lindy_d  FALSE  0.026 #> 8  Kimberly_w_Mail_3    Lindy_d  FALSE  0.046 #> 9     Kevin_h_Mail_2      Liz_t  FALSE  0.033 #> 10 Kimberly_w_Mail_3      Liz_t  FALSE  0.048 #> 11    Kevin_h_Mail_2   Louise_k  FALSE  0.014 #> 12 Kimberly_w_Mail_3   Louise_k  FALSE  0.027 #> 13    Kevin_h_Mail_2     Lynn_b  FALSE  0.017 #> 14 Kimberly_w_Mail_3     Lynn_b  FALSE  0.040 #> 15    Kevin_h_Mail_2     Lysa_a  FALSE  0.006 #> 16 Kimberly_w_Mail_3     Lysa_a  FALSE -0.018 #> 17    Kevin_h_Mail_2        M_f  FALSE  0.021 #> 18 Kimberly_w_Mail_3        M_f  FALSE  0.038 #> 19    Kevin_h_Mail_2        M_l  FALSE  0.016 #> 20 Kimberly_w_Mail_3        M_l  FALSE  0.047"},{"path":"https://andreanini.github.io/idiolect/dev/reference/performance.html","id":null,"dir":"Reference","previous_headings":"","what":"Performance evaluation — performance","title":"Performance evaluation — performance","text":"function used test performance authorship analysis method.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/performance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performance evaluation — performance","text":"","code":"performance(training, test = NULL, by = \"case\", progress = TRUE)"},{"path":"https://andreanini.github.io/idiolect/dev/reference/performance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performance evaluation — performance","text":"training data frame results evaluate, typically output authorship analysis function, impostors(). training present function perform leave-one-cross-validation. test Optional data frame results. present calibration model extracted training performance evaluated data set. Either \"case\" \"author\". performance evaluated leave-one-, \"case\" go table row row , \"author\" selected, performance calculated taking author (identified value K column). progress Logical. TRUE (default) progress bar diplayed.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/performance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Performance evaluation — performance","text":"function returns list containing data frame performance statistics, including object can used make tippet plot using tippet.plot() function ROC package (https://github.com/davidavdav/ROC).","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/performance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Performance evaluation — performance","text":"applying method real authorship case, good practice test known ground truth data. function performs test taking input either single table results two tables, one training one test, returning output list following performance statistics: log-likelihood ratio cost (\\(C_{llr}\\) \\(C_{llr}^{min}\\)), Equal Error Rate (ERR), mean values log-likelihood ratio -author (TRUE) different-author (FALSE) cases, Area Curve (AUC), Balanced Accuracy, Precision, Recall, F1, full confusion matrix. binary classification statistics calculated considering Log-Likelihood Ratio score 0 threshold.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/performance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Performance evaluation — performance","text":"","code":"results <- data.frame(score = c(0.5, 0.2, 0.8, 0.01), target = c(TRUE, FALSE, TRUE, FALSE)) perf <- performance(results) #>    |                                                                               |                                                                      |   0%   |                                                                               |=======================                                               |  33%   |                                                                               |===============================================                       |  67%   |                                                                               |======================================================================| 100% perf$evaluation #>        Cllr  Cllr_min EER Mean TRUE LLR Mean FALSE LLR TRUE trials FALSE trials #> 1 0.2422848 0.4150375  25      14.91206      -12.77601           4            4 #>   AUC Balanced Accuracy Precision Recall F1 TP FN FP TN #> 1   1                 1         1      1  1  2  0  0  2"},{"path":"https://andreanini.github.io/idiolect/dev/reference/posterior.html","id":null,"dir":"Reference","previous_headings":"","what":"Posterior prosecution probabilities and odds — posterior","title":"Posterior prosecution probabilities and odds — posterior","text":"function takes input value Log-Likelihood Ratio returns table shows impact simulated prior probabilities prosecution hypothesis.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/posterior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Posterior prosecution probabilities and odds — posterior","text":"","code":"posterior(LLR)"},{"path":"https://andreanini.github.io/idiolect/dev/reference/posterior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Posterior prosecution probabilities and odds — posterior","text":"LLR One single numeric value corresponding Log-Likelihood Ratio (base 10).","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/posterior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Posterior prosecution probabilities and odds — posterior","text":"data frame containing simulated prior probabilities/odds prosecution resulting posterior probabilities/odds LLR.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/posterior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Posterior prosecution probabilities and odds — posterior","text":"","code":"posterior(LLR = 0) #> # A tibble: 11 × 6 #>    prosecution_prior_probs prior_odds   LLR    LR  post_odds #>                      <dbl>      <dbl> <dbl> <dbl>      <dbl> #>  1                0.000001 0.00000100     0     1 0.00000100 #>  2                0.01     0.0101         0     1 0.0101     #>  3                0.1      0.111          0     1 0.111      #>  4                0.2      0.25           0     1 0.25       #>  5                0.3      0.429          0     1 0.429      #>  6                0.4      0.667          0     1 0.667      #>  7                0.5      1              0     1 1          #>  8                0.6      1.5            0     1 1.5        #>  9                0.7      2.33           0     1 2.33       #> 10                0.8      4              0     1 4          #> 11                0.9      9              0     1 9          #> # ℹ 1 more variable: prosecution_post_probs <dbl> posterior(LLR = 1.8) #> # A tibble: 11 × 6 #>    prosecution_prior_probs prior_odds   LLR    LR   post_odds #>                      <dbl>      <dbl> <dbl> <dbl>       <dbl> #>  1                0.000001 0.00000100   1.8  63.1   0.0000631 #>  2                0.01     0.0101       1.8  63.1   0.637     #>  3                0.1      0.111        1.8  63.1   7.01      #>  4                0.2      0.25         1.8  63.1  15.8       #>  5                0.3      0.429        1.8  63.1  27.0       #>  6                0.4      0.667        1.8  63.1  42.1       #>  7                0.5      1            1.8  63.1  63.1       #>  8                0.6      1.5          1.8  63.1  94.6       #>  9                0.7      2.33         1.8  63.1 147.        #> 10                0.8      4            1.8  63.1 252.        #> 11                0.9      9            1.8  63.1 568.        #> # ℹ 1 more variable: prosecution_post_probs <dbl> posterior(LLR = -0.5) #> # A tibble: 11 × 6 #>    prosecution_prior_probs prior_odds   LLR    LR   post_odds #>                      <dbl>      <dbl> <dbl> <dbl>       <dbl> #>  1                0.000001 0.00000100  -0.5 0.316 0.000000316 #>  2                0.01     0.0101      -0.5 0.316 0.00319     #>  3                0.1      0.111       -0.5 0.316 0.0351      #>  4                0.2      0.25        -0.5 0.316 0.0791      #>  5                0.3      0.429       -0.5 0.316 0.136       #>  6                0.4      0.667       -0.5 0.316 0.211       #>  7                0.5      1           -0.5 0.316 0.316       #>  8                0.6      1.5         -0.5 0.316 0.474       #>  9                0.7      2.33        -0.5 0.316 0.738       #> 10                0.8      4           -0.5 0.316 1.26        #> 11                0.9      9           -0.5 0.316 2.85        #> # ℹ 1 more variable: prosecution_post_probs <dbl> posterior(LLR = 4) #> # A tibble: 11 × 6 #>    prosecution_prior_probs prior_odds   LLR    LR  post_odds #>                      <dbl>      <dbl> <dbl> <dbl>      <dbl> #>  1                0.000001 0.00000100     4 10000     0.0100 #>  2                0.01     0.0101         4 10000   101.     #>  3                0.1      0.111          4 10000  1111.     #>  4                0.2      0.25           4 10000  2500      #>  5                0.3      0.429          4 10000  4286.     #>  6                0.4      0.667          4 10000  6667.     #>  7                0.5      1              4 10000 10000      #>  8                0.6      1.5            4 10000 15000      #>  9                0.7      2.33           4 10000 23333.     #> 10                0.8      4              4 10000 40000      #> 11                0.9      9              4 10000 90000      #> # ℹ 1 more variable: prosecution_post_probs <dbl>"},{"path":"https://andreanini.github.io/idiolect/dev/reference/tokenize_sents.html","id":null,"dir":"Reference","previous_headings":"","what":"Tokenize to sentences — tokenize_sents","title":"Tokenize to sentences — tokenize_sents","text":"function turns corpus texts quanteda tokens object sentences.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/tokenize_sents.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tokenize to sentences — tokenize_sents","text":"","code":"tokenize_sents(corpus, model = \"en_core_web_sm\")"},{"path":"https://andreanini.github.io/idiolect/dev/reference/tokenize_sents.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tokenize to sentences — tokenize_sents","text":"corpus quanteda corpus object, typically output create_corpus() function output contentmask(). model spacy model use. default \"en_core_web_sm\".","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/tokenize_sents.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tokenize to sentences — tokenize_sents","text":"quanteda tokens object token sentence.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/tokenize_sents.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tokenize to sentences — tokenize_sents","text":"function first split text paragraphs splitting new line markers uses spacy tokenize paragraph sentences. function accepts plain text corpus input output contentmask(). function necessary prepare data lambdaG().","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/tokenize_sents.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tokenize to sentences — tokenize_sents","text":"","code":"if (FALSE) { # \\dontrun{ toy.pos <- corpus(\"the N was on the N . he did n't move \\n N ; \\n N N\") tokenize_sents(toy.pos) } # }"},{"path":"https://andreanini.github.io/idiolect/dev/reference/vectorize.html","id":null,"dir":"Reference","previous_headings":"","what":"Vectorize data — vectorize","title":"Vectorize data — vectorize","text":"function turns texts feature vectors.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/vectorize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Vectorize data — vectorize","text":"","code":"vectorize(   input,   tokens,   remove_punct,   remove_symbols,   remove_numbers,   lowercase,   n,   weighting,   trim,   threshold )"},{"path":"https://andreanini.github.io/idiolect/dev/reference/vectorize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Vectorize data — vectorize","text":"input quanteda corpus object author names docvar called \"author\". Typically, output create_corpus() function. tokens type tokens extract, either \"character\" \"word\". remove_punct logical value. FALSE keep punctuation marks TRUE remove . remove_symbols logical value. TRUE removes symbols FALSE keeps . remove_numbers logical value. TRUE removes numbers FALSE keeps . lowercase logical value. TRUE transforms tokens lower case. n order size n-grams extracted. weighting type weighting use, \"rel\" relative frequencies, \"tf-idf\", \"boolean\". trim logical value. TRUE frequent tokens kept. threshold numeric value indicating many frequent tokens keep.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/vectorize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Vectorize data — vectorize","text":"dfm (document-feature matrix) containing text feature vector. N-gram tokenisation cross sentence boundaries.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/vectorize.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Vectorize data — vectorize","text":"authorship analysis functions call vectorize() standard parameters algorithm selected. function therefore left users want modify parameters convenience dfm reused algorithms avoid vectorizing data many times. users need run standard analysis need use function.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/reference/vectorize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Vectorize data — vectorize","text":"","code":"mycorpus <- quanteda::corpus(\"The cat sat on the mat.\") quanteda::docvars(mycorpus, \"author\") <- \"author1\" matrix <- vectorize(mycorpus, tokens = \"character\", remove_punct = FALSE, remove_symbols = TRUE, remove_numbers = TRUE, lowercase = TRUE, n = 5, weighting = \"rel\", trim = TRUE, threshold = 1500)"},{"path":"https://andreanini.github.io/idiolect/dev/news/index.html","id":"idiolect-development-version","dir":"Changelog","previous_headings":"","what":"idiolect (development version)","title":"idiolect (development version)","text":"create_corpus() tests correct syntax file names returns error correct (plus showing file names incorrect).","code":""},{"path":"https://andreanini.github.io/idiolect/dev/news/index.html","id":"idiolect-111","dir":"Changelog","previous_headings":"","what":"idiolect 1.1.1","title":"idiolect 1.1.1","text":"CRAN release: 2025-12-03 minor bug fixes concordance() now can take sentences input also show sentence boundaries lambdaG_visualize() can now text heatmap either sentences ordered lambdaG values (default) original order sentences text lambdaG_visualize() can now visualize negative lambdaG values html file ngram_tracing() contained major bug performing tests multiple known authors lead anomalously high incorrect performance statistics. fixed. performance() progress bar now can optional performance() can run leave-one-author rather just text","code":""},{"path":"https://andreanini.github.io/idiolect/dev/news/index.html","id":"idiolect-101","dir":"Changelog","previous_headings":"","what":"idiolect 1.0.1","title":"idiolect 1.0.1","text":"CRAN release: 2024-08-28 Fixed issues CRAN review.","code":""},{"path":"https://andreanini.github.io/idiolect/dev/news/index.html","id":"idiolect-100","dir":"Changelog","previous_headings":"","what":"idiolect 1.0.0","title":"idiolect 1.0.0","text":"Initial CRAN submission.","code":""}]
