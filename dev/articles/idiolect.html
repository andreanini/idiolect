<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>idiolect • idiolect</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png">
<link rel="icon" type="”image/svg+xml”" href="../favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" sizes="any" href="../favicon.ico">
<link rel="manifest" href="../site.webmanifest">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="idiolect">
<meta name="robots" content="noindex">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">idiolect</a>

    <small class="nav-text text-danger me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="In-development version">1.1.1.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item"><a class="nav-link" href="../articles/idiolect.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/andreanini/idiolect/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>idiolect</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/andreanini/idiolect/blob/main/vignettes/idiolect.Rmd" class="external-link"><code>vignettes/idiolect.Rmd</code></a></small>
      <div class="d-none name"><code>idiolect.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/andreanini/idiolect" class="external-link">idiolect</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; Loading required package: quanteda</span></span>
<span><span class="co">#&gt; Package version: 4.3.1</span></span>
<span><span class="co">#&gt; Unicode version: 15.1</span></span>
<span><span class="co">#&gt; ICU version: 74.2</span></span>
<span><span class="co">#&gt; Parallel computing: disabled</span></span>
<span><span class="co">#&gt; See https://quanteda.io for tutorials and examples.</span></span></code></pre></div>
<p><code>idiolect</code> is a package that depends on
<code>quanteda</code> for all the main Natural Language Processing
functions. Although the basic object types and functions are described
in detail in the documentation of this package, familiarity with
<code>quanteda</code> is highly recommended. More information about
<code>quanteda</code> can be found on its <a href="http://quanteda.io" class="external-link">website</a>.</p>
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>Authorship Analysis is defined as the task of determining the
likelihood that a certain candidate is the author of a certain set of
questioned or disputed texts. We call <em>Forensic</em> Authorship
Analysis a task of this kind applied in a real forensic case.</p>
<p>In Forensic Linguistics, typically:</p>
<ul>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
indicates the set of disputed or <em>questioned</em> texts.</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>
indicates the texts written by the candidate author and collected as
comparison material.</li>
</ul>
<p>We then indicate with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>R</mi><annotation encoding="application/x-tex">R</annotation></semantics></math>
the reference dataset that might have to be compiled by the analyst for
the specific case <span class="citation">(Ishihara et al.
2024)</span>.</p>
<p>As an example, the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
text could be a text committing a crime, such as a threatening letter,
or some text that is evidence in an investigation, such as a set of text
messages.
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>
would then be the set of texts authored by the suspect author of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>.
Finally,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>R</mi><annotation encoding="application/x-tex">R</annotation></semantics></math>
would be made up of texts that are comparable to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>,
for example in genre/register, mode of production, and any other
parameter that the linguist maintains as being important for the
analysis in the particular case.</p>
<p>A crucial difference between Authorship Analysis and Forensic
Authorship Analysis is that whereas the former can be treated as a
classification task where the final answer is binary (‘candidate is the
author’ vs. ‘candidate is NOT the author’), the latter needs an
expression of likelihood for the two competing propositions or
hypotheses, the Prosecution Hypothesis
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>H</mi><mi>p</mi></msub><annotation encoding="application/x-tex">H_p</annotation></semantics></math>
vs. the Defence Hypothesis
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>H</mi><mi>d</mi></msub><annotation encoding="application/x-tex">H_d</annotation></semantics></math>,
for example:</p>
<div class="line-block">
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>H</mi><mi>p</mi></msub><annotation encoding="application/x-tex">H_p</annotation></semantics></math>:
The author of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>
and the author of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
are the same individual.<br><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>H</mi><mi>d</mi></msub><annotation encoding="application/x-tex">H_d</annotation></semantics></math>:
The author of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>
and the author of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
are two different individuals.</div>
<p>The job of the forensic linguist in a forensic context is to analyse
the linguistic evidence and determine which hypothesis it supports and
with what degree of strength, thus aiding the trier-of-fact in reaching
a conclusion. The role of the forensic linguist is therefore not to
provide a YES/NO answer but rather to express the strength of the
evidence in favour of each of these two hypotheses.</p>
<p>Given
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>R</mi><annotation encoding="application/x-tex">R</annotation></semantics></math>,
the workflow for this analysis involves four steps:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Preparation</strong>: This step involves any pre-processing
step that is necessary for the analysis with the chosen method.</li>
<li>
<strong>Validation</strong>: Carry out an analysis on the case data
or on a separate dataset that has been designed to be similar to the
case material in order to validate that the chosen method works for this
particular case. Even though all the methods contained in
<code>idiolect</code> have been tested in various published academic
studies, it is also important that the methods are tested
(i.e. <em>validated</em>) for any specific case <span class="citation">(Ishihara et al. 2024)</span>.</li>
<li>
<strong>Analysis</strong>: Carry out the analysis on the real
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>,
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>R</mi><annotation encoding="application/x-tex">R</annotation></semantics></math>.</li>
<li>
<strong>Calibration</strong>: Turn the output of (3) into a
Likelihood Ratio that expresses the strength of the evidence given the
two competing hypotheses.</li>
</ol>
</div>
<div class="section level2">
<h2 id="preparation">Preparation<a class="anchor" aria-label="anchor" href="#preparation"></a>
</h2>
<p>The input for the key functions of <code>idiolect</code> is a
<code>quanteda</code> corpus object with two <code>docvars</code>:
<em>author</em>, containing the unique names of the authors of each
text, and <em>textname</em>, the name of each text. Users can create
this corpus using <code>quanteda</code>. For guidance on how to create a
corpus with <code>quanteda</code> see <a href="https://quanteda.io/articles/quickstart.html" class="external-link">this page</a>.</p>
<p>However, for users who are less experienced with
<code>quanteda</code>, <code>idiolect</code> has a convenience function
called <code><a href="../reference/create_corpus.html">create_corpus()</a></code> to import texts in this format
starting from a folder of plain texts. This function is simply calling
<code>readtext</code> (therefore this package must be installed) while
scanning the name of the files for the metadata of each text,
specifically the name of the author and the name of the file. The syntax
to follow to name the files is:</p>
<div class="line-block">authorname_textname.txt
(e.g. smith_text1.txt).</div>
<p>Assuming that a folder of plain text files with names according to
this syntax are ready on the user’s computer, then the following command
(not executed here) loads the folder as a <code>quanteda</code> corpus
object containing the required <code>docvars</code>.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">corpus</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/create_corpus.html">create_corpus</a></span><span class="op">(</span><span class="st">"path/to/folder"</span><span class="op">)</span></span></code></pre></div>
<p>In this vignette, instead, the rest of the workflow is demonstrated
using a small dataset of the Enron corpus that is included in this
package (see <code><a href="../reference/enron.sample.html">?enron.sample</a></code>).</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">corpus</span> <span class="op">&lt;-</span> <span class="va">enron.sample</span></span></code></pre></div>
<p>This corpus is a <code>quanteda</code> corpus object that contains
ten authors with approximately the same amount of data.</p>
<div class="section level3">
<h3 id="content-masking">Content masking<a class="anchor" aria-label="anchor" href="#content-masking"></a>
</h3>
<p>A highly recommended and sometimes necessary pre-processing step is
content masking. This step consists in masking or removing words or
other tokens in the text that are likely to create noise for an
authorship analysis. Hiding content not only avoids incorrectly
attributing a text based on the correlation between topics and authors
<span class="citation">(Bischoff et al. 2020)</span> but also tends to
improve the performance of authorship analysis methods in cross-topic
and cross-genre situations <span class="citation">(Stamatatos
2017)</span>.</p>
<p>Three content masking methods are implemented in
<code>idiolect</code>: (1) the <em>POSnoise</em> algorithm developed by
<span class="citation">Halvani and Graner (2021)</span>; (2) the
<em>frame n-grams</em> approach introduced by <span class="citation">Nini (2023)</span>; and (3) an implementation of the
<em>TextDistortion</em> approach originally introduced by <span class="citation">Stamatatos (2017)</span>. These options are available
in the <code><a href="../reference/contentmask.html">contentmask()</a></code> function. Because this function
depends on <a href="https://spacyr.quanteda.io/reference/spacyr-package.html" class="external-link"><code>spacyr</code></a>
and this requires downloading a parsing model for a language for the
automatic tagging of Parts of Speech (e.g. nouns, adjectives, adverbs),
this function is not run in this vignette. Instead, the Enron sample has
already been content-masked using <em>POSnoise</em>, as can be seen from
the preview of the corpus</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">corpus</span></span>
<span><span class="co">#&gt; Corpus consisting of 49 documents and 2 docvars.</span></span>
<span><span class="co">#&gt; Kevin_h_Mail_1 :</span></span>
<span><span class="co">#&gt; "N N N N wants to be N when he V up likes N P , N for doing t..."</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Kevin_h_Mail_3 :</span></span>
<span><span class="co">#&gt; "i 've V a J one , but the only N N N i have is on a N N from..."</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Kevin_h_Mail_4 :</span></span>
<span><span class="co">#&gt; "this was J towards the N of a J N N N . in N , P P helped th..."</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Kevin_h_Mail_5 :</span></span>
<span><span class="co">#&gt; "V the N for more than D N may get you V . a N N with a N and..."</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Kevin_h_Mail_2 :</span></span>
<span><span class="co">#&gt; "P , here 's the J N on our P P N V to V the V needs of the P..."</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Kimberly_w_Mail_3 :</span></span>
<span><span class="co">#&gt; "they also have J N at the J N of P D per N and only a D J ea..."</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [ reached max_ndoc ... 43 more documents ]</span></span></code></pre></div>
<p>The <em>POSnoise</em> algorithm essentially replaces all words that
tend to contain meaning (nouns, verbs, adjectives, adverbs) with their
Part of Speech tag (N, V, J, B) while all the other words or tokens are
left unchanged. In addition to this operation, <em>POSnoise</em>
contains a white list of content words that mostly tend to be functional
in English, such as verbs like <em>do</em>, <em>have</em>, <em>make</em>
or adverbs such as <em>consequently</em>, <em>therefore</em>.</p>
<p>The following code should be used to run the
<code><a href="../reference/contentmask.html">contentmask()</a></code> function. This will require installing and
initiating a <a href="https://spacy.io" class="external-link"><em>spacy</em></a> parsing model
for the language chosen. This process should happen automatically.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">posnoised.corpus</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/contentmask.html">contentmask</a></span><span class="op">(</span><span class="va">corpus</span>, model <span class="op">=</span> <span class="st">"en_core_web_sm"</span>, algorithm <span class="op">=</span> <span class="st">"POSnoise"</span><span class="op">)</span></span></code></pre></div>
<p>If the installation did not start automatically, then the
installatino of the <code>spacyr</code> package and of the default model
can be done as follows:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html" class="external-link">install.packages</a></span><span class="op">(</span><span class="st">"spacyr"</span><span class="op">)</span></span>
<span><span class="fu">spacyr</span><span class="fu">::</span><span class="fu">install_spacy</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="data-labelling">Data labelling<a class="anchor" aria-label="anchor" href="#data-labelling"></a>
</h3>
<p>In this example it is simulated that <em>Kimberly_w_Mail_3</em>,
written by the author <em>Kimberly_w</em>, is the real
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
text and all the other known texts written by <em>Kimberly_w</em> are
therefore the set of known texts
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>.
The remaining texts from the other authors are the reference samples
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>R</mi><annotation encoding="application/x-tex">R</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Q</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://quanteda.io/reference/corpus_subset.html" class="external-link">corpus_subset</a></span><span class="op">(</span><span class="va">corpus</span>, <span class="va">author</span> <span class="op">==</span> <span class="st">"Kimberly_w"</span> <span class="op">&amp;</span> <span class="va">textname</span> <span class="op">==</span> <span class="st">"Mail_3"</span><span class="op">)</span></span>
<span><span class="va">K</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://quanteda.io/reference/corpus_subset.html" class="external-link">corpus_subset</a></span><span class="op">(</span><span class="va">corpus</span>, <span class="va">author</span> <span class="op">==</span> <span class="st">"Kimberly_w"</span> <span class="op">&amp;</span> <span class="va">textname</span> <span class="op">!=</span> <span class="st">"Mail_3"</span><span class="op">)</span></span>
<span><span class="va">R</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://quanteda.io/reference/corpus_subset.html" class="external-link">corpus_subset</a></span><span class="op">(</span><span class="va">corpus</span>, <span class="va">author</span> <span class="op">!=</span> <span class="st">"Kimberly_w"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="vectorisation">Vectorisation<a class="anchor" aria-label="anchor" href="#vectorisation"></a>
</h3>
<p>Before applying certain authorship analysis methods, each text or
sample must be turned into a numerical representation called a
<em>feature vector</em>, a process typically referred to as
<em>vectorisation</em>. <code>idiolect</code> has a function to
vectorise a corpus called <code><a href="../reference/vectorize.html">vectorize()</a></code>. The features
normally used by many authorship analysis methods are
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>-grams
of words and punctuation marks or characters. For example, the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
text can be vectorised into the relative frequencies of its words using
this code.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/vectorize.html">vectorize</a></span><span class="op">(</span><span class="va">Q</span>, tokens <span class="op">=</span> <span class="st">"word"</span>, remove_punct <span class="op">=</span> <span class="cn">FALSE</span>, remove_symbols <span class="op">=</span> <span class="cn">TRUE</span>, remove_numbers <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>          lowercase <span class="op">=</span> <span class="cn">TRUE</span>, n <span class="op">=</span> <span class="fl">1</span>, weighting <span class="op">=</span> <span class="st">"rel"</span>, trim <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span>max_nfeat <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="co">#&gt; Document-feature matrix of: 1 document, 136 features (0.00% sparse) and 2 docvars.</span></span>
<span><span class="co">#&gt;                    features</span></span>
<span><span class="co">#&gt; docs                      they        also      have</span></span>
<span><span class="co">#&gt;   Kimberly_w_Mail_3 0.00289296 0.009643202 0.0192864</span></span>
<span><span class="co">#&gt; [ reached max_nfeat ... 133 more features ]</span></span></code></pre></div>
<p>or, as the most frequent 1000 character 4-grams relative frequencies,
for example, using</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/vectorize.html">vectorize</a></span><span class="op">(</span><span class="va">Q</span>, tokens <span class="op">=</span> <span class="st">"character"</span>, remove_punct <span class="op">=</span> <span class="cn">FALSE</span>, remove_symbols <span class="op">=</span> <span class="cn">TRUE</span>, remove_numbers <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>          lowercase <span class="op">=</span> <span class="cn">TRUE</span>, n <span class="op">=</span> <span class="fl">4</span>, weighting <span class="op">=</span> <span class="st">"rel"</span>, trim <span class="op">=</span> <span class="cn">TRUE</span>, threshold <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span>max_nfeat <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="co">#&gt; Document-feature matrix of: 1 document, 1,094 features (0.00% sparse) and 2 docvars.</span></span>
<span><span class="co">#&gt;                    features</span></span>
<span><span class="co">#&gt; docs                        they         hey          ey a</span></span>
<span><span class="co">#&gt;   Kimberly_w_Mail_3 0.0009771987 0.0009771987 0.0003257329</span></span>
<span><span class="co">#&gt; [ reached max_nfeat ... 1,091 more features ]</span></span></code></pre></div>
<p>The output of the function is a <code>quanteda</code>
<em>document-feature matrix</em> (or <em>dfm</em>) that can efficiently
store even very large matrices.</p>
<p>This <code><a href="../reference/vectorize.html">vectorize()</a></code> function is mostly designed for expert
users because different choices in the parameters of the vectorisation
can be made using each single authorship analysis method function. In
addition, since most authorship analysis methods already have a default
setting of these parameters, these are already the default for the
authorship analysis functions.</p>
<p>This step is therefore not necessary unless there are specific
requirements, as any vectorisation is handled by the functions that
apply the authorship analysis methods.</p>
</div>
</div>
<div class="section level2">
<h2 id="validation">Validation<a class="anchor" aria-label="anchor" href="#validation"></a>
</h2>
<p>The first step of the validation is to remove the real
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
text. This is the actual forensic sample to analyse and it must be
therefore removed when validating the analysis. The validation set is
therefore made up of only the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>R</mi><annotation encoding="application/x-tex">R</annotation></semantics></math>
datasets</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">validation</span> <span class="op">&lt;-</span> <span class="va">K</span> <span class="op">+</span> <span class="va">R</span></span></code></pre></div>
<p>This dataset must now be re-divided into ‘fake’
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
texts and ‘fake’
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>
texts.</p>
<p>To create two new disjoint datasets, <code>validation.Q</code> and
<code>validation.K</code>, we randomly sample one text for each author
to be the ‘fake’
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
and we leave the rest to be their ‘fake’
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>
texts.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">validation.Q</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://quanteda.io/reference/corpus_sample.html" class="external-link">corpus_sample</a></span><span class="op">(</span><span class="va">validation</span>, size <span class="op">=</span> <span class="fl">1</span>, by <span class="op">=</span> <span class="va">author</span><span class="op">)</span></span>
<span><span class="va">validation.K</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://quanteda.io/reference/corpus_subset.html" class="external-link">corpus_subset</a></span><span class="op">(</span><span class="va">validation</span>, <span class="op">!</span><span class="fu"><a href="https://quanteda.io/reference/docnames.html" class="external-link">docnames</a></span><span class="op">(</span><span class="va">validation</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="fu"><a href="https://quanteda.io/reference/docnames.html" class="external-link">docnames</a></span><span class="op">(</span><span class="va">validation.Q</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>This is not the only way in which a validation analysis can be
conducted. A completely different dataset that is similar to the case
data could be used, for example. This simpler approach is more suitable
for this small example.</p>
<div class="section level3">
<h3 id="authorship-analysis">Authorship analysis<a class="anchor" aria-label="anchor" href="#authorship-analysis"></a>
</h3>
<p>In this example, the scenario simulated is a <em>verification</em>:
was the unknown
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
text written by the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>
author, <em>Kimberly_w</em>? For this reason, the method chosen is one
of the most successful authorship verification methods available at
present, the <em>Impostors Method</em> <span class="citation">(Koppel
and Winter 2014)</span>, and in particular one of its latest variants
called the <em>Rank-Based Impostors Method</em> <span class="citation">(Potha and Stamatatos 2017, 2020)</span>.</p>
<p>This analysis can be run in <code>idiolect</code> using the function
<code><a href="../reference/impostors.html">impostors()</a></code> and then selecting the default parameter for
the <em>algorithm</em> argument, “<em>RBI</em>”. The main argument of
this function are the <em>q.data</em>, which is the set of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
texts to test, and the <em>k.data</em>, which is the set of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>
texts from one or more authors that are going to be tested, and finally
the set of impostors data, <em>cand.imps</em>. For this example, the
impostors data is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>R</mi><annotation encoding="application/x-tex">R</annotation></semantics></math>
set but generally the recommendation is to use another dataset when
possible.</p>
<p>The <code><a href="../reference/impostors.html">impostors()</a></code> function accepts more than one author in
<em>k.data</em> and it also accepts the same dataset as input for both
<em>k.data</em> and <em>cand.imps</em>. When the same dataset is used,
<code><a href="../reference/impostors.html">impostors()</a></code> will test each author in <em>k.data</em> and
use the texts written by other authors as impostors.</p>
<p>In contrast to other authorship analysis functions like
<code><a href="../reference/delta.html">delta()</a></code> and <code><a href="../reference/ngram_tracing.html">ngram_tracing()</a></code>,
<code><a href="../reference/impostors.html">impostors()</a></code> does not offer additional parameters to modify
the vectorisation process because all the Impostors Method algorithms
already have a well-specified default setting. If the user wants to
change these they should then vectorise the corpus separately using
<code><a href="../reference/vectorize.html">vectorize()</a></code> and then use the <em>dfm</em> as the input of
<code><a href="../reference/impostors.html">impostors()</a></code>.</p>
<p>The RBI variant of the method requires setting a parameter called
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>,
which is the number of most similar impostors texts to sample from the
wider set of impostors. The recommended setting is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>100</mn></mrow><annotation encoding="application/x-tex">k=100</annotation></semantics></math>
or
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>300</mn></mrow><annotation encoding="application/x-tex">k=300</annotation></semantics></math>
but for simplicity this is set to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>10</mn></mrow><annotation encoding="application/x-tex">k=10</annotation></semantics></math>
in this example. This is not a realistic setting and it is used here
only as an example.</p>
<p>Because an analysis using the Impostors Method can have long run
times, this function can also be parallelised using more than one
core.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/impostors.html">impostors</a></span><span class="op">(</span><span class="va">validation.Q</span>, <span class="va">validation.K</span>, <span class="va">validation.K</span>, algorithm <span class="op">=</span> <span class="st">"RBI"</span>, k <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code></pre></div>
<p>The output of <code><a href="../reference/impostors.html">impostors()</a></code> is a data frame showing the
results of comparing each
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>
author with each
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
text. The variable <em>target</em> is TRUE if the comparison is a
same-author one or FALSE if it is a different-author one. The variable
<em>score</em> contains the Impostors score, which is a value that
ranges from 0 to 1. Other authorship analysis functions return the same
data frame type with the same columns. The variable <em>score</em>
therefore represents different quantities depending on the analysis
function used (e.g. for <code><a href="../reference/delta.html">delta()</a></code>, this is the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Δ</mi><annotation encoding="application/x-tex">\Delta</annotation></semantics></math>
coefficient, and so on).</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">res</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span>,<span class="op">]</span></span>
<span><span class="co">#&gt;             K                 Q target score</span></span>
<span><span class="co">#&gt; 1  Kimberly_w    Kevin_h_Mail_1  FALSE 0.750</span></span>
<span><span class="co">#&gt; 2  Kimberly_w Kimberly_w_Mail_5   TRUE 1.000</span></span>
<span><span class="co">#&gt; 3  Kimberly_w    Larry_c_Mail_2  FALSE 0.500</span></span>
<span><span class="co">#&gt; 4  Kimberly_w    Lindy_d_Mail_3  FALSE 0.833</span></span>
<span><span class="co">#&gt; 5  Kimberly_w      Liz_t_Mail_4  FALSE 0.667</span></span>
<span><span class="co">#&gt; 6  Kimberly_w   Louise_k_Mail_2  FALSE 0.667</span></span>
<span><span class="co">#&gt; 7  Kimberly_w     Lynn_b_Mail_3  FALSE 1.000</span></span>
<span><span class="co">#&gt; 8  Kimberly_w     Lysa_a_Mail_5  FALSE 0.500</span></span>
<span><span class="co">#&gt; 9  Kimberly_w        M_f_Mail_3  FALSE 0.750</span></span>
<span><span class="co">#&gt; 10 Kimberly_w        M_l_Mail_2  FALSE 0.833</span></span></code></pre></div>
<p>In order to assess the results of this validation analysis, the
function <code><a href="../reference/performance.html">performance()</a></code> can be used to return a series of
performance metrics. This function can take one or two result data
frames as input. If two are provided, then one is used as training and
the other one as test. If only one data frame is provided, then the
performance metrics are calculated using a leave-one-out approach.</p>
<p>The procedure followed by this function is to held out one text (if
leave-one-out, otherwise the test dataset in its entirety) and then use
the rest of the data (or the training dataset) as a calibration dataset
to calculate a <em>Log-Likelihood Ratio</em>
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>L</mi><mi>R</mi></mrow><annotation encoding="application/x-tex">LLR</annotation></semantics></math>).
This analysis is done using the <code><a href="../reference/calibrate_LLR.html">calibrate_LLR()</a></code> function,
which fits a logistic regression model to calibrate the score into a
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>L</mi><mi>R</mi></mrow><annotation encoding="application/x-tex">LLR</annotation></semantics></math><span class="citation">Ishihara (2021)</span> using the <code>ROC</code>
library <span class="citation">(Leeuwen 2015)</span>.</p>
<p>The output of the function is the following:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/performance.html">performance</a></span><span class="op">(</span><span class="va">res</span>, progress <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">p</span><span class="op">$</span><span class="va">evaluation</span></span>
<span><span class="co">#&gt;        Cllr  Cllr_min      EER Mean TRUE LLR Mean FALSE LLR TRUE trials</span></span>
<span><span class="co">#&gt; 1 0.7979282 0.7183427 26.26582     0.4062006     -0.4368895          12</span></span>
<span><span class="co">#&gt;   FALSE trials       AUC Balanced Accuracy Precision Recall        F1 TP FN FP</span></span>
<span><span class="co">#&gt; 1           92 0.7766667         0.7666667      0.25    0.8 0.3809524  8  2 24</span></span>
<span><span class="co">#&gt;   TN</span></span>
<span><span class="co">#&gt; 1 66</span></span></code></pre></div>
<p>The
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>C</mi><mrow><mi>l</mi><mi>l</mi><mi>r</mi></mrow></msub><annotation encoding="application/x-tex">C_{llr}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>C</mi><mrow><mi>l</mi><mi>l</mi><mi>r</mi></mrow><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msubsup><annotation encoding="application/x-tex">C_{llr}^{min}</annotation></semantics></math>
coefficients are used to evaluate the performance of the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>L</mi><mi>R</mi></mrow><annotation encoding="application/x-tex">LLR</annotation></semantics></math>
system <span class="citation">(Ramos et al. 2013)</span>. These
coefficients estimate the accuracy of the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>L</mi><mi>R</mi></mrow><annotation encoding="application/x-tex">LLR</annotation></semantics></math>,
where a value of 1 indicates chance-level accuracy and a lower
coefficient
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mrow><mi>l</mi><mi>l</mi><mi>r</mi></mrow></msub><mo>&lt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">C_{llr}&lt;1</annotation></semantics></math>
suggests that there is valuable information in the results, with lower
values of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>C</mi><mrow><mi>l</mi><mi>l</mi><mi>r</mi></mrow></msub><annotation encoding="application/x-tex">C_{llr}</annotation></semantics></math>
suggesting better performance. The other binary classification metrics
returned, such as Precision, Recall, and F1, are all calculated using
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>L</mi><mi>R</mi><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">LLR &gt; 0</annotation></semantics></math>
as the threshold for a TRUE (or same-author in this case)
classification.</p>
<p>In the present example, a
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mrow><mi>l</mi><mi>l</mi><mi>r</mi></mrow></msub><mo>=</mo></mrow><annotation encoding="application/x-tex">C_{llr}=</annotation></semantics></math>
0.798 suggests that the performance is acceptable to be able to proceed
with the actual forensic analysis. The
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>C</mi><mrow><mi>l</mi><mi>l</mi><mi>r</mi></mrow><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msubsup><annotation encoding="application/x-tex">C_{llr}^{min}</annotation></semantics></math>,
which is the component of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>C</mi><mrow><mi>l</mi><mi>l</mi><mi>r</mi></mrow></msub><annotation encoding="application/x-tex">C_{llr}</annotation></semantics></math>
measuring the amount of discrimination, is even lower, which means that
there is a substantial difference in the two distributions. This is
confirmed by the Area Under the Curve value of 0.777. Because of the
large disparity between the TRUE and FALSE test cases, the values of
Precision and F1 are misleading. The Balanced Accuracy value of 0.767,
however, again suggests a substantial amount of discrimination at
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>L</mi><mi>R</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">LLR=0</annotation></semantics></math>.</p>
<p>The results of the analysis can also be plotted using a density plot
for each of the two distributions, TRUE and FALSE. This can be done
using the <code><a href="../reference/density_plot.html">density_plot()</a></code> function</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/density_plot.html">density_plot</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span></span></code></pre></div>
<p><img src="idiolect_files/figure-html/unnamed-chunk-17-1.png" class="r-plt" alt="" width="660"></p>
<p>This plot shows the values of the score on the horizontal axis and
the density for TRUE (blue) vs. FALSE (red) on the vertical axis.</p>
<p>These findings are evidence that the method is validated for this
dataset and it is now possible to analyse the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
text and use these results to calibrate the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>L</mi><mi>R</mi></mrow><annotation encoding="application/x-tex">LLR</annotation></semantics></math>
for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>.</p>
</div>
</div>
<div class="section level2">
<h2 id="analysis-of-q">Analysis of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math><a class="anchor" aria-label="anchor" href="#analysis-of-q"></a>
</h2>
<p>At this point the only thing left to do is to analyse the forensic
data by feeding the real
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>,
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>R</mi><annotation encoding="application/x-tex">R</annotation></semantics></math>
into the <code><a href="../reference/impostors.html">impostors()</a></code> function using the same settings used
for the validation.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">q.res</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/impostors.html">impostors</a></span><span class="op">(</span><span class="va">Q</span>, <span class="va">K</span>, <span class="va">R</span>, algorithm <span class="op">=</span> <span class="st">"RBI"</span>, k <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code></pre></div>
<p>Because there is only one
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
text, the final table of results only contains one row</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">q.res</span></span>
<span><span class="co">#&gt;            K                 Q target score</span></span>
<span><span class="co">#&gt; 1 Kimberly_w Kimberly_w_Mail_3   TRUE     1</span></span></code></pre></div>
<div class="section level3">
<h3 id="qualitative-examination-of-evidence">Qualitative examination of evidence<a class="anchor" aria-label="anchor" href="#qualitative-examination-of-evidence"></a>
</h3>
<p>Before reaching the conclusions, it is often important to inspect the
features that the algorithm has considered for the analysis. In a
forensic analysis, good knowledge of the data is important and best
practice require the analyst to be very familiar with the dataset before
running a computational analysis. Reading the data and being familiar
with it can lead to the addition of more pre-processing steps to remove
noise and can help the analyst spot any problem mistakenly introduced by
the algorithm.</p>
<p>In addition to familiarise themselves with the data,
<code>idiolect</code> allows the analyst to explore the most important
feature considered by the authorship analysis method used. For example,
when using the RBI algorithm with <code><a href="../reference/impostors.html">impostors()</a></code> then the
parameter <em>features</em> can be switched to TRUE to obtain a list of
important features. Running this again with this parameter switched on
produces the following results</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">q.res2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/impostors.html">impostors</a></span><span class="op">(</span><span class="va">Q</span>, <span class="va">K</span>, <span class="va">R</span>, algorithm <span class="op">=</span> <span class="st">"RBI"</span>, k <span class="op">=</span> <span class="fl">10</span>, features <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/strwrap.html" class="external-link">strwrap</a></span><span class="op">(</span><span class="va">q.res2</span><span class="op">$</span><span class="va">features</span>, width <span class="op">=</span> <span class="fl">70</span><span class="op">)</span></span>
<span><span class="co">#&gt;  [1] "to me|o me |, her| P on|P on |re al|ve no|i jus|lso ,|so , |P P f|N N"</span></span>
<span><span class="co">#&gt;  [2] ".|also |ll me|l me | also| N i |e N s| few |you n|ou ne|u nee|our"    </span></span>
<span><span class="co">#&gt;  [3] "J|ur J |ust w|st wa|few N|ew N |P P V|ve a | him |as i | , he|u"      </span></span>
<span><span class="co">#&gt;  [4] "and|the J|he J |V J N|u hav|, i w|P P i|N N N|P P o|, N a|do no|o"    </span></span>
<span><span class="co">#&gt;  [5] "not|P D .|you h|ou ha| too |re is|s for|r N o| P in|P in |our P|ur P" </span></span>
<span><span class="co">#&gt;  [6] "| P fo|P for| may | at t|e a N|o V i| P to|P to |o be |lso V|so V"    </span></span>
<span><span class="co">#&gt;  [7] "|thing|hing |V it |is J |r N w|P , h|nd th|ou an|to do|o do | two |"  </span></span>
<span><span class="co">#&gt;  [8] "we w| do n|rom P|om P | N fr|ave n|e N w| here|t is |but i|, i h|"    </span></span>
<span><span class="co">#&gt;  [9] "into|into | we V| yet |you N|ou N |ke a | V it|ave a|ng th|s N N|n P" </span></span>
<span><span class="co">#&gt; [10] ",| our |s you|N fro|ere i|N who|me N | see | N or|N or |is V | can |" </span></span>
<span><span class="co">#&gt; [11] "we '|ut i | V wi|V wit|P , w|V our|N for| but |an V | one |ome N| N"  </span></span>
<span><span class="co">#&gt; [12] "fo|ave b|or V |other| to m| is o| a N | J N |e hav|J N o|e tha|"      </span></span>
<span><span class="co">#&gt; [13] "look|i am | , bu|, but|eithe|ither|P P .|t wan|can V|t to |in P |in V"</span></span>
<span><span class="co">#&gt; [14] "|to se| N J |ore N| get |N in |N , N| as i| in P|e is |ith y|th yo|h" </span></span>
<span><span class="co">#&gt; [15] "you|e J N|ve V | , th|n N .| i ha|some | is J|are a|e an |i hav|"     </span></span>
<span><span class="co">#&gt; [16] "othe|this | a J |a N N|my N | is a| J fo|J for|e thi|n our|s the|may" </span></span>
<span><span class="co">#&gt; [17] "b|ay be|y be |ase l|se le|e let|o see|did n|o hav| V ou| it .|"       </span></span>
<span><span class="co">#&gt; [18] "some|or P | N on| P 's|P 's | is V| so i|d the|d you| , i |e P P|n"   </span></span>
<span><span class="co">#&gt; [19] "you|if yo| you |is a |the N|he N | B , |P , P|t V a|and t| this|N on" </span></span>
<span><span class="co">#&gt; [20] "|a N t|V tha|want |in a |e wil|a N f| , so|ther |we ar| have|i wil|"  </span></span>
<span><span class="co">#&gt; [21] "my N|have | P N |o V o| V J |hat P|r N a|t the|a J N| V an| 's N|'s N"</span></span>
<span><span class="co">#&gt; [22] "|P P P| the | N if|N if | P is|at i | work| on P|on P |with |N , b|N" </span></span>
<span><span class="co">#&gt; [23] "has|a N a|ant t|nt to|ow if|w if |V and|ake a| in a|e of | are |is N" </span></span>
<span><span class="co">#&gt; [24] "|as V | week|week | J in|J in | N of|N of |e V i|V to |or N |, we |to"</span></span>
<span><span class="co">#&gt; [25] "be| to b|N N o|e you| V to| V my|V my |r J N| V fo|V for|you t|V thi|"</span></span>
<span><span class="co">#&gt; [26] "to s| know|e N N|V in |f you| , wh| V a |me to| N in|t kno|u to |ed"  </span></span>
<span><span class="co">#&gt; [27] "to|his N|P P N|fter | me t| star|start|the P|he P |know |for t|out w|"</span></span>
<span><span class="co">#&gt; [28] "'ll | N th| was |now i|N V N| afte|P , a|r N i|ere w|ach o|ch of|h of"</span></span>
<span><span class="co">#&gt; [29] "|o J N|i 'll|after|r D N|ill h| it t|ether|e als|P tha|o V .|"        </span></span>
<span><span class="co">#&gt; [30] "only|nning|ning |y N N|e V y|ou to| out |se V |ase V|J N ,| just|"    </span></span>
<span><span class="co">#&gt; [31] "each|each |ill V|t you|eek .|are V|look |o mak|only |ou wo| P D |l"   </span></span>
<span><span class="co">#&gt; [32] "hav|worki|orkin|rking|to ma|at yo|tart | N P |our N|ur N | both|both" </span></span>
<span><span class="co">#&gt; [33] "|e in | of N|of N |J N .|V you| give|N N a|and g|just |at P |o the|t" </span></span>
<span><span class="co">#&gt; [34] "V i|e and|s to | in t|here |V any|o V y| by N|ll V |o you| , as|, as" </span></span>
<span><span class="co">#&gt; [35] "|N we |e J t|in th| , we|n the|needs|eeds |ll ha|for N|hat y| N we|re"</span></span>
<span><span class="co">#&gt; [36] "V |N N ,|N N i|your |s N ,|is th|ve an|by th| V yo| , yo|,"           </span></span>
<span><span class="co">#&gt; [37] "you|pleas|lease|ease |re J | call|e nee|y N .| and |make |P is |N"    </span></span>
<span><span class="co">#&gt; [38] "tha|ough |by N | if y|t i w|s tha|V a N| is t|o V u| me a|her N|you"  </span></span>
<span><span class="co">#&gt; [39] "a|e V a|call |V the| any |er N | be V|be V |e wou|or th| plea| she"   </span></span>
<span><span class="co">#&gt; [40] "|at we|more |P P a| P th| J , |or D |we ne|e to | P , | we n|ing o|t" </span></span>
<span><span class="co">#&gt; [41] "thi| V in| that|r P P|we wo| N an|e N .|N and|o V N| J to|J to | P V" </span></span>
<span><span class="co">#&gt; [42] "|d to | V N |ch N | has | did | V on|hat i|V P P|r our| N by|N by |th"</span></span>
<span><span class="co">#&gt; [43] "N | a fe|a few|V N o| a D |d lik|e V f|i wou|hat h|ke to|ill n|"      </span></span>
<span><span class="co">#&gt; [44] "find|find |ld li|uld l| per | let |N , s|N , h|ike t|ve be|e bee|for" </span></span>
<span><span class="co">#&gt; [45] "h|y hav|s N w| woul|would| like|like |e if | be J|be J |ith P|th P"   </span></span>
<span><span class="co">#&gt; [46] "|in N |e V t| P ha|give |ow wh|ee if|you m|and i|o V t| to V|to V |"  </span></span>
<span><span class="co">#&gt; [47] "on t| with|ted t|or yo| , pl|, ple|P and|at th| make|for y|t me |now" </span></span>
<span><span class="co">#&gt; [48] "w|not V|and h| P an|o P P|let m|et me| me k|me kn|e kno|ith N| V up|V"</span></span>
<span><span class="co">#&gt; [49] "up | i am| in N|any N|ny N |J N N| will|ot V |d P P| i V | , P |r N"  </span></span>
<span><span class="co">#&gt; [50] ".|f the|ould |eed t| N wi|nd i | for |ome o|me of|t wit|f N .|o V w|" </span></span>
<span><span class="co">#&gt; [51] "N so|N so |m to |ne of|e V .|king | them|them |one o|to ta|n to |we"  </span></span>
<span><span class="co">#&gt; [52] "ha| your|id no|see i|hat N|e J .|ave V| N B |nd N |o V a| of y|of"    </span></span>
<span><span class="co">#&gt; [53] "yo|and N| N N | what| to t|to ge|o get|a N o| if t|e V N| we h| V"    </span></span>
<span><span class="co">#&gt; [54] "th|i nee|if we|f we |oing |r the| from| had | N , |d not|e N o|u V t|"</span></span>
<span><span class="co">#&gt; [55] "want|need |from | , N |N V t"</span></span></code></pre></div>
<p>The RBI method uses as features character 4-grams and a list of these
features is clearly hard to interpret by a human analyst. Despite the
complexity, this is not an impossible task. <code>idiolect</code> offers
a function to aid exploration called <code><a href="../reference/concordance.html">concordance()</a></code>, which
uses <code>quanteda</code>’s <code><a href="https://quanteda.io/reference/kwic.html" class="external-link">kwic()</a></code> as its engine.</p>
<p><code><a href="../reference/concordance.html">concordance()</a></code> takes as input a string representing one
or more words (or punctuation marks). For example, one of the most
important character 4-gram seems to be &lt;<em>, her</em>&gt; so this
could be the search target.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/concordance.html">concordance</a></span><span class="op">(</span><span class="va">Q</span>, <span class="va">K</span>, <span class="va">R</span>, search <span class="op">=</span> <span class="st">", her"</span>, token.type <span class="op">=</span> <span class="st">"character"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span><span class="va">pre</span>, <span class="va">node</span>, <span class="va">post</span>, <span class="va">authorship</span><span class="op">)</span></span>
<span><span class="co">#&gt;      pre  node  post authorship</span></span>
<span><span class="co">#&gt; 1   . P  , her e is           Q</span></span>
<span><span class="co">#&gt; 2  we V  , her e is           Q</span></span>
<span><span class="co">#&gt; 3   . P  , her e is           Q</span></span>
<span><span class="co">#&gt; 4  ur N  , her e is           K</span></span>
<span><span class="co">#&gt; 5   . P  , her e is           K</span></span>
<span><span class="co">#&gt; 6   . P  , her e is           K</span></span>
<span><span class="co">#&gt; 7  nd P  , her e is           K</span></span>
<span><span class="co">#&gt; 8   . P  , her e is           K</span></span>
<span><span class="co">#&gt; 9   N N  , her e is           K</span></span>
<span><span class="co">#&gt; 10 st P  , her e is           K</span></span>
<span><span class="co">#&gt; 11  N N  , her e is           K</span></span>
<span><span class="co">#&gt; 12    P  , her e 's   Reference</span></span>
<span><span class="co">#&gt; 13  P P  , her e out  Reference</span></span>
<span><span class="co">#&gt; 14 nd P  , her e is   Reference</span></span>
<span><span class="co">#&gt; 15  . P  , her e are  Reference</span></span>
<span><span class="co">#&gt; 16  . P  , her e are  Reference</span></span></code></pre></div>
<p>The search reveals that this character sequence is a strong
characteristic of the candidate author’s writing. However, the real
underlying pattern is not the use of a comma followed by the possessive
determiner <em>her</em> but the token sequence [<em>, here is</em>],
which is only used by the candidate author and one other author in the
reference corpus.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/concordance.html">concordance</a></span><span class="op">(</span><span class="va">Q</span>, <span class="va">K</span>, <span class="va">R</span>, search <span class="op">=</span> <span class="st">", here is"</span>, token.type <span class="op">=</span> <span class="st">"word"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span><span class="va">pre</span>, <span class="va">node</span>, <span class="va">post</span>, <span class="va">authorship</span><span class="op">)</span></span>
<span><span class="co">#&gt;                 pre      node                   post authorship</span></span>
<span><span class="co">#&gt; 1   each of you . P , here is           the P P P on          Q</span></span>
<span><span class="co">#&gt; 2    on this N we V , here is          a N N of both          Q</span></span>
<span><span class="co">#&gt; 3       N for P . P , here is            the P P P P          Q</span></span>
<span><span class="co">#&gt; 4  all . per your N , here is          some J N on P          K</span></span>
<span><span class="co">#&gt; 5       B and V . P , here is           the J N N on          K</span></span>
<span><span class="co">#&gt; 6         N V N . P , here is            the P P P P          K</span></span>
<span><span class="co">#&gt; 7       N . P and P , here is        the J for the P          K</span></span>
<span><span class="co">#&gt; 8       N N yet . P , here is            the P P P P          K</span></span>
<span><span class="co">#&gt; 9    out of the N N , here is the beginning of the N          K</span></span>
<span><span class="co">#&gt; 10 N on this past P , here is  the N we talked about          K</span></span>
<span><span class="co">#&gt; 11   as per our N N , here is            the V P P P          K</span></span>
<span><span class="co">#&gt; 12   know . P and P , here is            a N of N in  Reference</span></span></code></pre></div>
<p>Another important feature is represented by the two character
4-grams, &lt;<em>lso ,</em>&gt; and &lt;<em>so ,</em> &gt;, which are
likely to refer to the token sequence [<em>also ,</em>].</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/concordance.html">concordance</a></span><span class="op">(</span><span class="va">Q</span>, <span class="va">K</span>, <span class="va">R</span>, search <span class="op">=</span> <span class="st">"lso ,"</span>, token.type <span class="op">=</span> <span class="st">"character"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span><span class="va">pre</span>, <span class="va">node</span>, <span class="va">post</span>, <span class="va">authorship</span><span class="op">)</span></span>
<span><span class="co">#&gt;      pre  node  post authorship</span></span>
<span><span class="co">#&gt; 1  N ? a lso ,  ther          Q</span></span>
<span><span class="co">#&gt; 2  V . a lso ,  i ha          Q</span></span>
<span><span class="co">#&gt; 3  P . a lso ,  plea          Q</span></span>
<span><span class="co">#&gt; 4  k . a lso ,  P ha          Q</span></span>
<span><span class="co">#&gt; 5  N . a lso ,  P P           K</span></span>
<span><span class="co">#&gt; 6  N . a lso ,  at t          K</span></span>
<span><span class="co">#&gt; 7  N ? a lso ,  i 'v          K</span></span>
<span><span class="co">#&gt; 8  s . a lso ,  let           K</span></span>
<span><span class="co">#&gt; 9      a lso ,  V th          K</span></span>
<span><span class="co">#&gt; 10 N . a lso ,  i V           K</span></span>
<span><span class="co">#&gt; 11 N . a lso ,  woul  Reference</span></span>
<span><span class="co">#&gt; 12 . P a lso ,  V to  Reference</span></span>
<span><span class="co">#&gt; 13 N . a lso ,  any   Reference</span></span>
<span><span class="co">#&gt; 14 N . a lso ,  have  Reference</span></span>
<span><span class="co">#&gt; 15 P . a lso ,  P P   Reference</span></span>
<span><span class="co">#&gt; 16 N . a lso ,  you   Reference</span></span>
<span><span class="co">#&gt; 17 D . a lso ,  to V  Reference</span></span>
<span><span class="co">#&gt; 18 N . a lso ,  tell  Reference</span></span>
<span><span class="co">#&gt; 19 J . a lso ,  coul  Reference</span></span>
<span><span class="co">#&gt; 20 N . a lso ,  we n  Reference</span></span>
<span><span class="co">#&gt; 21 J . a lso ,  ther  Reference</span></span></code></pre></div>
<p>This is correct and it is referring to the use of <em>also</em> at
the beginning of a sentence and immediately followed by a comma.</p>
<p>Although searching all the features returned is clearly a significant
amount of work, by inspecting the list of features carefully and by
using <code><a href="../reference/concordance.html">concordance()</a></code> to explore the features in the data the
analyst can spot patterns or mistakes in the analysis <span class="citation">(Ypma, Ramos, and Meuwly 2023)</span>.</p>
</div>
<div class="section level3">
<h3 id="conclusions">Conclusions<a class="anchor" aria-label="anchor" href="#conclusions"></a>
</h3>
<p>Although the score assigned to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
is high, depending on the calibration data, it can correspond to various
magnitudes of the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>L</mi><mi>R</mi></mrow><annotation encoding="application/x-tex">LLR</annotation></semantics></math>.</p>
<p>The
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>L</mi><mi>R</mi></mrow><annotation encoding="application/x-tex">LLR</annotation></semantics></math>
value for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
can also be plotted onto the TRUE vs. FALSE distributions using the
second argument of <code><a href="../reference/density_plot.html">density_plot()</a></code>. The <em>q</em> argument
can be used to draw a black vertical line that crosses the two
distributions at the horizontal axis corresponding to the score of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/density_plot.html">density_plot</a></span><span class="op">(</span><span class="va">res</span>, q <span class="op">=</span> <span class="va">q.res</span><span class="op">$</span><span class="va">score</span><span class="op">)</span></span></code></pre></div>
<p><img src="idiolect_files/figure-html/unnamed-chunk-26-1.png" class="r-plt" alt="" width="660"></p>
<p>To perform this calibration the <code><a href="../reference/calibrate_LLR.html">calibrate_LLR()</a></code> function
is used again by using the validation results as calibration data</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">q.llr</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/calibrate_LLR.html">calibrate_LLR</a></span><span class="op">(</span><span class="va">res</span>, <span class="va">q.res</span>, latex <span class="op">=</span> <span class="cn">T</span><span class="op">)</span></span>
<span><span class="va">q.llr</span><span class="op">$</span><span class="va">`Verbal label`</span></span>
<span><span class="co">#&gt; [1] "Moderate support for $H_p$"</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/strwrap.html" class="external-link">strwrap</a></span><span class="op">(</span><span class="va">q.llr</span><span class="op">$</span><span class="va">Interpretation</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "The similarity is 13.24 times more likely to be observed in the case of"</span></span>
<span><span class="co">#&gt; [2] "$H_p$ than in the case of $H_d$"</span></span></code></pre></div>
<p>This function not only returns the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>L</mi><mi>R</mi></mrow><annotation encoding="application/x-tex">LLR</annotation></semantics></math>
value but also the verbal labels and their interpretation <span class="citation">(Marquis et al. 2016)</span>.</p>
<p>The final conclusion of the analysis is therefore the following:</p>
<blockquote>
<p>The similarity score of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
given
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>
is 1, which corresponds to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>L</mi><mi>R</mi><mo>=</mo></mrow><annotation encoding="application/x-tex">LLR=</annotation></semantics></math>
1.122. The similarity is 13.24 times more likely to be observed in the
case of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>H</mi><mi>p</mi></msub><annotation encoding="application/x-tex">H_p</annotation></semantics></math>
than in the case of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>H</mi><mi>d</mi></msub><annotation encoding="application/x-tex">H_d</annotation></semantics></math>.
Therefore, the linguistic analysis offers <strong>Moderate support for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>H</mi><mi>p</mi></msub><annotation encoding="application/x-tex">H_p</annotation></semantics></math></strong>.</p>
</blockquote>
<p>This conclusion can be complemented with an explanation of the
implication of these results for the trier of facts by showing a table
of posterior probabilities assuming a range of prior probabilities. This
can be done with the <code><a href="../reference/posterior.html">posterior()</a></code> function by inserting as
input the value of the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>L</mi><mi>R</mi></mrow><annotation encoding="application/x-tex">LLR</annotation></semantics></math></p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/posterior.html">posterior</a></span><span class="op">(</span><span class="va">q.llr</span><span class="op">$</span><span class="va">LLR</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span><span class="va">prosecution_prior_probs</span>, <span class="va">prosecution_post_probs</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 11 × 2</span></span></span>
<span><span class="co">#&gt;    prosecution_prior_probs prosecution_post_probs</span></span>
<span><span class="co">#&gt;                      <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>                  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 1</span>                0.000<span style="text-decoration: underline;">001</span>              0.000<span style="text-decoration: underline;">013</span>2</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 2</span>                0.01                  0.118    </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 3</span>                0.1                   0.595    </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 4</span>                0.2                   0.768    </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 5</span>                0.3                   0.850    </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 6</span>                0.4                   0.898    </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 7</span>                0.5                   0.930    </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 8</span>                0.6                   0.952    </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 9</span>                0.7                   0.969    </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">10</span>                0.8                   0.981    </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">11</span>                0.9                   0.992</span></span></code></pre></div>
<p>The table above reveals that, assuming a prior probability for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>H</mi><mi>p</mi></msub><annotation encoding="application/x-tex">H_p</annotation></semantics></math>
of 0.00001 (roughly, one out of the population of Manchester), then this
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>L</mi><mi>R</mi></mrow><annotation encoding="application/x-tex">LLR</annotation></semantics></math>
would transform this probability to a posterior probability for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>H</mi><mi>p</mi></msub><annotation encoding="application/x-tex">H_p</annotation></semantics></math>
of 0.000013. In other words, it would not make much substantial
difference for the trial.</p>
<p>However, if the prior probability of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>H</mi><mi>p</mi></msub><annotation encoding="application/x-tex">H_p</annotation></semantics></math>
was 0.5, then these results would turn it to 0.93, which is a
substantial change.</p>
<p>The table shows that the present evidence could change the
probability that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>H</mi><mi>p</mi></msub><annotation encoding="application/x-tex">H_p</annotation></semantics></math>
is true to equal or higher than 0.9 only with a prior greater than
0.4.</p>
</div>
</div>
<div class="section level2">
<h2 id="acknowledgements">Acknowledgements<a class="anchor" aria-label="anchor" href="#acknowledgements"></a>
</h2>
<p>I would like to thank Shunichi Ishihara and Marie Bojsen-Møller for
helpful comments on the first draft of this vignette.</p>
</div>
<div class="section level2">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-bischoff" class="csl-entry">
Bischoff, Sebastian, Niklas Deckers, Marcel Schliebs, Ben Thies,
Matthias Hagen, Efstathios Stamatatos, Benno Stein, and Martin Potthast.
2020. <span>“The Importance of Suppressing Domain Style in Authorship
Analysis.”</span> <a href="https://arxiv.org/abs/2005.14714" class="external-link">https://arxiv.org/abs/2005.14714</a>.
</div>
<div id="ref-halvani2021" class="csl-entry">
Halvani, Oren, and Lukas Graner. 2021. <span>“<span>POSNoise</span>:
<span>An Effective Countermeasure Against Topic Biases</span> in
<span>Authorship Analysis</span>.”</span> In <em>Proceedings of the 16th
<span>International Conference</span> on <span>Availability</span>,
<span>Reliability</span> and <span>Security</span></em>, 1–12. Vienna,
Austria: Association for Computing Machinery. <a href="https://doi.org/10.1145/3465481.3470050" class="external-link">https://doi.org/10.1145/3465481.3470050</a>.
</div>
<div id="ref-ishihara2021" class="csl-entry">
Ishihara, Shunichi. 2021. <span>“Score-Based Likelihood Ratios for
Linguistic Text Evidence with a Bag-of-Words Model.”</span> <em>Forensic
Science International</em> 327: 110980. <a href="https://doi.org/10.1016/j.forsciint.2021.110980" class="external-link">https://doi.org/10.1016/j.forsciint.2021.110980</a>.
</div>
<div id="ref-ishihara2024" class="csl-entry">
Ishihara, Shunichi, Sonia Kulkarni, Michael Carne, Sabine Ehrhardt, and
Andrea Nini. 2024. <span>“Validation in Forensic Text Comparison: Issues
and Opportunities.”</span> <em>Languages</em> 9 (2): 47. <a href="https://doi.org/10.3390/languages9020047" class="external-link">https://doi.org/10.3390/languages9020047</a>.
</div>
<div id="ref-koppel2014" class="csl-entry">
Koppel, Moshe, and Yaron Winter. 2014. <span>“Determining If Two
Documents Are Written by the Same Author.”</span> <em>Journal of the
Association for Information Science and Technology</em> 65 (1): 178–87.
</div>
<div id="ref-vanleeuwen2015" class="csl-entry">
Leeuwen, David A. van. 2015. <span>“ROC: Compute Structures to Compute
ROC and DET Plots and Metrics for 2-Class Classifiers.”</span> <a href="https://rdrr.io/github/davidavdav/ROC/" class="external-link">https://rdrr.io/github/davidavdav/ROC/</a>.
</div>
<div id="ref-marquis2016" class="csl-entry">
Marquis, Raymond, Alex Biedermann, Liv Cadola, Christophe Champod, Line
Gueissaz, Geneviève Massonnet, Williams David Mazzella, Franco Taroni,
and Tacha Hicks. 2016. <span>“Discussion on How to Implement a Verbal
Scale in a Forensic Laboratory: Benefits, Pitfalls and Suggestions to
Avoid Misunderstandings.”</span> <em>Science &amp; Justice</em> 56 (5):
364–70. <a href="https://doi.org/10.1016/j.scijus.2016.05.009" class="external-link">https://doi.org/10.1016/j.scijus.2016.05.009</a>.
</div>
<div id="ref-morrison2013" class="csl-entry">
Morrison, Geoffrey Stewart. 2013. <span>“Tutorial on Logistic-Regression
Calibration and Fusion: Converting a Score to a Likelihood
Ratio.”</span> <em>Australian Journal of Forensic Sciences</em> 45 (2):
173–97. <a href="https://doi.org/10.1080/00450618.2012.733025" class="external-link">https://doi.org/10.1080/00450618.2012.733025</a>.
</div>
<div id="ref-nini2023" class="csl-entry">
Nini, Andrea. 2023. <em>A Theory of Linguistic Individuality for
Authorship Analysis</em>. Elements in Forensic Linguistics. Cambridge,
UK: Cambridge University Press.
</div>
<div id="ref-potha2017" class="csl-entry">
Potha, Nektaria, and Efstathios Stamatatos. 2017. <span>“An
<span>Improved Impostors Method</span> for <span>Authorship
Verification</span>.”</span> In <em>Experimental <span>IR Meets
Multilinguality</span>, <span>Multimodality</span>, and
<span>Interaction</span></em>, edited by Gareth J. F. Jones, Séamus
Lawless, Julio Gonzalo, Liadh Kelly, Lorraine Goeuriot, Thomas Mandl,
Linda Cappellato, and Nicola Ferro, 10456:138–44. Lecture
<span>Notes</span> in <span>Computer Science</span>. Springer, Cham.
</div>
<div id="ref-potha2020" class="csl-entry">
———. 2020. <span>“Improved Algorithms for Extrinsic Author
Verification.”</span> <em>Knowledge and Information Systems</em> 62 (5):
1903–21. <a href="https://doi.org/10.1007/s10115-019-01408-4" class="external-link">https://doi.org/10.1007/s10115-019-01408-4</a>.
</div>
<div id="ref-ramos2013" class="csl-entry">
Ramos, Daniel, Joaquin Gonzalez-Rodriguez, Grzegorz Zadora, and Colin
Aitken. 2013. <span>“Information-Theoretical Assessment of the
Performance of Likelihood Ratio Computation Methods.”</span> <em>Journal
of Forensic Sciences</em> 58 (6): 1503–18. <a href="https://doi.org/10.1111/1556-4029.12233" class="external-link">https://doi.org/10.1111/1556-4029.12233</a>.
</div>
<div id="ref-stamatatos2017" class="csl-entry">
Stamatatos, Efstathios. 2017. <span>“Authorship <span>Attribution Using
Text Distortion</span>.”</span> In <em>Proceedings of the 15th
<span>Conference</span> of the <span>European Chapter</span> of the
<span>Association</span> for <span>Computational Linguistics</span>:
<span>Volume</span> 1, <span>Long Papers</span></em>, 1138–49. Valencia,
Spain: Association for Computational Linguistics.
</div>
<div id="ref-ypma2023" class="csl-entry">
Ypma, Rolf J. F., Daniel Ramos, and Didier Meuwly. 2023. <span>“<span class="nocase">AI-based Forensic Evaluation</span> in
<span>Court</span>: <span>The Desirability</span> of
<span>Explanation</span> and the <span>Necessity</span> of
<span>Validation</span>.”</span> In <em>Artificial
<span>Intelligence</span> (<span>AI</span>) in <span>Forensic
Sciences</span></em>, edited by Zeno Geradts and Katrin Franke, 3–17.
Forensic <span>Science</span> in <span>Focus</span>. Hoboken, NJ: Wiley.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Andrea Nini.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
